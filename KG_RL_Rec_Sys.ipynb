{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aWXPH78vnF4x","executionInfo":{"status":"ok","timestamp":1689932959862,"user_tz":-60,"elapsed":2650,"user":{"displayName":"huan chen","userId":"01704466685251061733"}},"outputId":"976bbfed-5422-49f3-b2f2-e0944440b1fe"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://download.pytorch.org/whl/cpu/torch_stable.html\n","\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.0.1 (from versions: 1.11.0, 1.11.0+cpu, 1.12.0, 1.12.0+cpu, 1.12.1, 1.12.1+cpu, 1.13.0, 1.13.0+cpu, 1.13.1, 1.13.1+cpu, 2.0.0, 2.0.0+cpu, 2.0.1, 2.0.1+cpu)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.0.1\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip3 install torch==1.0.1 torchvision==0.2.2 -f https://download.pytorch.org/whl/cpu/torch_stable.html"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0-g61FN7nF4z","executionInfo":{"status":"ok","timestamp":1689932968070,"user_tz":-60,"elapsed":6612,"user":{"displayName":"huan chen","userId":"01704466685251061733"}},"outputId":"c22a7b01-59e6-439f-aaad-b79b01b22239"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: easydict in /usr/local/lib/python3.10/dist-packages (1.10)\n"]}],"source":["!pip3 install easydict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dKHTX4UMnF4z"},"outputs":[],"source":["# Proprocess the data, create kg etc.\n","from __future__ import absolute_import, division, print_function\n","\n","import os\n","import pickle\n","import gzip\n","\n","import data_utils\n","import utils\n","\n","from utils import *\n","from data_utils import ChallengeDataset, ChallengeDataLoader\n","from knowledge_graph import KnowledgeGraph"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ukmt20xbnF4z","executionInfo":{"status":"ok","timestamp":1689933039966,"user_tz":-60,"elapsed":33829,"user":{"displayName":"huan chen","userId":"01704466685251061733"}},"outputId":"b7f72fac-773b-4ebe-ade2-879371d4658a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Load challenge dataset from file...\n","Load user of size 463\n","Load article of size 71\n","Load word of size 2246\n","Load related_article of size 71\n","Load topic of size 55\n","Load product of size 64\n","Load topic_tag of size 24\n","Load product_tag of size 45\n","Load has_topic of size 71\n","Load has_product of size 71\n","Load also_response of size 71\n","Load recommended_together of size 71\n","Load response_together of size 71\n","Load has_topic_tag of size 71\n","Load has_product_tag of size 71\n","Load text of size 26172 word count= 10415868\n","Create word sampling rate\n","Create challenge knowledge graph from dataset...\n","Load entities...\n","Total 3039 nodes.\n","Load text...\n","Total 269374 text edges.\n","Load knowledge has_topic...\n","Total 566 has_topic edges.\n","Load knowledge has_product...\n","Total 720 has_product edges.\n","Load knowledge also_response...\n","Total 7318 also_response edges.\n","Load knowledge recommended_together...\n","Total 534 recommended_together edges.\n","Load knowledge response_together...\n","Total 142 response_together edges.\n","Load knowledge has_topic_tag...\n","Total 132 has_topic_tag edges.\n","Load knowledge has_product_tag...\n","Total 284 has_product_tag edges.\n","Remove duplicates...\n","Compute node degrees...\n","Generate challenge train/test labels.\n"]}],"source":["def generate_labels(dataset, mode='train'):\n","    review_file = '{}/{}.txt'.format(DATASET_DIR[dataset], mode)\n","    user_articles = {}  # {uid: [aid,...], ...}\n","    with open(review_file, 'r') as f:\n","        for line in f:\n","            line = line.strip()\n","            arr = line.split('\\t')\n","            user_idx = int(arr[0])\n","            article_idx = int(arr[1])\n","            if user_idx not in user_articles:\n","                user_articles[user_idx] = []\n","            user_articles[user_idx].append(article_idx)\n","    save_labels(dataset, user_articles, mode=mode)\n","\n","\n","def main(data):\n","    dataset_n = data\n","\n","    # Create Dataset instance for dataset.\n","    # ========== BEGIN ========== #\n","    print('Load', dataset_n, 'dataset from file...')\n","    if not os.path.isdir(TMP_DIR[dataset_n]):\n","        os.makedirs(TMP_DIR[dataset_n])\n","    dataset = ChallengeDataset(DATASET_DIR[dataset_n])\n","    save_dataset(dataset_n, dataset)\n","\n","    # Generate knowledge graph instance.\n","    # ========== BEGIN ========== #\n","\n","    print('Create', dataset_n, 'knowledge graph from dataset...')\n","    dataset = load_dataset(dataset_n)\n","    kg = KnowledgeGraph(dataset)\n","    kg.compute_degrees()\n","    save_kg(dataset_n, kg)\n","    # =========== END =========== #\n","\n","    # Genereate train/test labels.\n","    # ========== BEGIN ========== #\n","    print('Generate', dataset_n, 'train/test labels.')\n","    generate_labels(dataset_n, 'train')\n","    generate_labels(dataset_n, 'test')\n","    # =========== END =========== #\n","\n","\n","if __name__ == '__main__':\n","    main(\"challenge\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0TCEwPMMnF40"},"outputs":[],"source":["import sys\n","import random\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","from transe_model import KnowledgeEmbedding"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ic8cR_2MnF40","executionInfo":{"status":"ok","timestamp":1689933998461,"user_tz":-60,"elapsed":958046,"user":{"displayName":"huan chen","userId":"01704466685251061733"}},"outputId":"e103599a-acf0-4a74-d965-d43a250df21d"},"outputs":[{"output_type":"stream","name":"stdout","text":["./tmp/Challenge_Dataset/train_transe_model\n","[INFO]  Epoch: 01 | Words: 30827/10415869 | Lr: 0.00500 | Smooth loss: 39.49833\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 30827/10415869 | Lr: 0.00500 | Smooth loss: 39.49833\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 61780/10415869 | Lr: 0.00500 | Smooth loss: 37.77728\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 61780/10415869 | Lr: 0.00500 | Smooth loss: 37.77728\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 92723/10415869 | Lr: 0.00500 | Smooth loss: 37.07936\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 92723/10415869 | Lr: 0.00500 | Smooth loss: 37.07936\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 123830/10415869 | Lr: 0.00500 | Smooth loss: 36.51798\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 123830/10415869 | Lr: 0.00500 | Smooth loss: 36.51798\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 154269/10415869 | Lr: 0.00500 | Smooth loss: 35.52363\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 154269/10415869 | Lr: 0.00500 | Smooth loss: 35.52363\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 183348/10415869 | Lr: 0.00500 | Smooth loss: 34.90006\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 183348/10415869 | Lr: 0.00500 | Smooth loss: 34.90006\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 213167/10415869 | Lr: 0.00500 | Smooth loss: 34.72231\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 213167/10415869 | Lr: 0.00500 | Smooth loss: 34.72231\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 244052/10415869 | Lr: 0.00500 | Smooth loss: 34.58449\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 244052/10415869 | Lr: 0.00500 | Smooth loss: 34.58449\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 274489/10415869 | Lr: 0.00500 | Smooth loss: 34.43543\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 274489/10415869 | Lr: 0.00500 | Smooth loss: 34.43543\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 305945/10415869 | Lr: 0.00500 | Smooth loss: 33.54977\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 305945/10415869 | Lr: 0.00500 | Smooth loss: 33.54977\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 335998/10415869 | Lr: 0.00500 | Smooth loss: 33.16567\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 335998/10415869 | Lr: 0.00500 | Smooth loss: 33.16567\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 365960/10415869 | Lr: 0.00500 | Smooth loss: 32.98292\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 365960/10415869 | Lr: 0.00500 | Smooth loss: 32.98292\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 396122/10415869 | Lr: 0.00500 | Smooth loss: 32.37168\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 396122/10415869 | Lr: 0.00500 | Smooth loss: 32.37168\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 426143/10415869 | Lr: 0.00500 | Smooth loss: 32.30630\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 426143/10415869 | Lr: 0.00500 | Smooth loss: 32.30630\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 456853/10415869 | Lr: 0.00500 | Smooth loss: 31.99874\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 456853/10415869 | Lr: 0.00500 | Smooth loss: 31.99874\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 487742/10415869 | Lr: 0.00500 | Smooth loss: 31.49220\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 487742/10415869 | Lr: 0.00500 | Smooth loss: 31.49220\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 516764/10415869 | Lr: 0.00500 | Smooth loss: 30.72921\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 516764/10415869 | Lr: 0.00500 | Smooth loss: 30.72921\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 547682/10415869 | Lr: 0.00500 | Smooth loss: 30.49934\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 547682/10415869 | Lr: 0.00500 | Smooth loss: 30.49934\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 577187/10415869 | Lr: 0.00500 | Smooth loss: 29.72039\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 577187/10415869 | Lr: 0.00500 | Smooth loss: 29.72039\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 608021/10415869 | Lr: 0.00500 | Smooth loss: 29.03732\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 608021/10415869 | Lr: 0.00500 | Smooth loss: 29.03732\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 637748/10415869 | Lr: 0.00500 | Smooth loss: 28.67369\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 637748/10415869 | Lr: 0.00500 | Smooth loss: 28.67369\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 667396/10415869 | Lr: 0.00500 | Smooth loss: 28.53159\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 667396/10415869 | Lr: 0.00500 | Smooth loss: 28.53159\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 698274/10415869 | Lr: 0.00500 | Smooth loss: 28.09199\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 698274/10415869 | Lr: 0.00500 | Smooth loss: 28.09199\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 728225/10415869 | Lr: 0.00500 | Smooth loss: 27.43574\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 728225/10415869 | Lr: 0.00500 | Smooth loss: 27.43574\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 758326/10415869 | Lr: 0.00500 | Smooth loss: 28.13001\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 758326/10415869 | Lr: 0.00500 | Smooth loss: 28.13001\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 788171/10415869 | Lr: 0.00500 | Smooth loss: 27.67152\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 788171/10415869 | Lr: 0.00500 | Smooth loss: 27.67152\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 818937/10415869 | Lr: 0.00500 | Smooth loss: 27.55322\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 818937/10415869 | Lr: 0.00500 | Smooth loss: 27.55322\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 850176/10415869 | Lr: 0.00500 | Smooth loss: 27.44127\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 850176/10415869 | Lr: 0.00500 | Smooth loss: 27.44127\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 881082/10415869 | Lr: 0.00500 | Smooth loss: 27.55702\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 881082/10415869 | Lr: 0.00500 | Smooth loss: 27.55702\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 911326/10415869 | Lr: 0.00500 | Smooth loss: 27.10729\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 911326/10415869 | Lr: 0.00500 | Smooth loss: 27.10729\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 942421/10415869 | Lr: 0.00500 | Smooth loss: 27.27067\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 942421/10415869 | Lr: 0.00500 | Smooth loss: 27.27067\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 972116/10415869 | Lr: 0.00500 | Smooth loss: 27.53006\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 972116/10415869 | Lr: 0.00500 | Smooth loss: 27.53006\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1003983/10415869 | Lr: 0.00500 | Smooth loss: 27.23773\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1003983/10415869 | Lr: 0.00500 | Smooth loss: 27.23773\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1034286/10415869 | Lr: 0.00500 | Smooth loss: 26.59984\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1034286/10415869 | Lr: 0.00500 | Smooth loss: 26.59984\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1064632/10415869 | Lr: 0.00500 | Smooth loss: 26.56890\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1064632/10415869 | Lr: 0.00500 | Smooth loss: 26.56890\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1095356/10415869 | Lr: 0.00500 | Smooth loss: 27.04987\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1095356/10415869 | Lr: 0.00500 | Smooth loss: 27.04987\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1124268/10415869 | Lr: 0.00500 | Smooth loss: 26.65875\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1124268/10415869 | Lr: 0.00500 | Smooth loss: 26.65875\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1154079/10415869 | Lr: 0.00500 | Smooth loss: 26.97829\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1154079/10415869 | Lr: 0.00500 | Smooth loss: 26.97829\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1184238/10415869 | Lr: 0.00500 | Smooth loss: 26.69676\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1184238/10415869 | Lr: 0.00500 | Smooth loss: 26.69676\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1213820/10415869 | Lr: 0.00500 | Smooth loss: 26.94465\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1213820/10415869 | Lr: 0.00500 | Smooth loss: 26.94465\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1244898/10415869 | Lr: 0.00500 | Smooth loss: 26.82822\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1244898/10415869 | Lr: 0.00500 | Smooth loss: 26.82822\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1275065/10415869 | Lr: 0.00500 | Smooth loss: 27.13662\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1275065/10415869 | Lr: 0.00500 | Smooth loss: 27.13662\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1305133/10415869 | Lr: 0.00500 | Smooth loss: 26.53963\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1305133/10415869 | Lr: 0.00500 | Smooth loss: 26.53963\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1335698/10415869 | Lr: 0.00500 | Smooth loss: 26.06331\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1335698/10415869 | Lr: 0.00500 | Smooth loss: 26.06331\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1366357/10415869 | Lr: 0.00500 | Smooth loss: 26.36453\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1366357/10415869 | Lr: 0.00500 | Smooth loss: 26.36453\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1396701/10415869 | Lr: 0.00500 | Smooth loss: 26.43630\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1396701/10415869 | Lr: 0.00500 | Smooth loss: 26.43630\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1426917/10415869 | Lr: 0.00500 | Smooth loss: 26.39211\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1426917/10415869 | Lr: 0.00500 | Smooth loss: 26.39211\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1456523/10415869 | Lr: 0.00500 | Smooth loss: 26.09135\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1456523/10415869 | Lr: 0.00500 | Smooth loss: 26.09135\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1486068/10415869 | Lr: 0.00500 | Smooth loss: 26.01161\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1486068/10415869 | Lr: 0.00500 | Smooth loss: 26.01161\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1515301/10415869 | Lr: 0.00500 | Smooth loss: 25.18628\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1515301/10415869 | Lr: 0.00500 | Smooth loss: 25.18628\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1544860/10415869 | Lr: 0.00500 | Smooth loss: 25.69133\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1544860/10415869 | Lr: 0.00500 | Smooth loss: 25.69133\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1574829/10415869 | Lr: 0.00500 | Smooth loss: 26.31322\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1574829/10415869 | Lr: 0.00500 | Smooth loss: 26.31322\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1605235/10415869 | Lr: 0.00500 | Smooth loss: 26.30368\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1605235/10415869 | Lr: 0.00500 | Smooth loss: 26.30368\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1636530/10415869 | Lr: 0.00500 | Smooth loss: 25.14540\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1636530/10415869 | Lr: 0.00500 | Smooth loss: 25.14540\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1666932/10415869 | Lr: 0.00500 | Smooth loss: 26.69552\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1666932/10415869 | Lr: 0.00500 | Smooth loss: 26.69552\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1697150/10415869 | Lr: 0.00500 | Smooth loss: 24.95513\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1697150/10415869 | Lr: 0.00500 | Smooth loss: 24.95513\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1727422/10415869 | Lr: 0.00500 | Smooth loss: 25.75463\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1727422/10415869 | Lr: 0.00500 | Smooth loss: 25.75463\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1757671/10415869 | Lr: 0.00500 | Smooth loss: 25.50345\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1757671/10415869 | Lr: 0.00500 | Smooth loss: 25.50345\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1787416/10415869 | Lr: 0.00500 | Smooth loss: 25.28104\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1787416/10415869 | Lr: 0.00500 | Smooth loss: 25.28104\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1817582/10415869 | Lr: 0.00500 | Smooth loss: 25.82554\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1817582/10415869 | Lr: 0.00500 | Smooth loss: 25.82554\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1847523/10415869 | Lr: 0.00500 | Smooth loss: 25.01700\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1847523/10415869 | Lr: 0.00500 | Smooth loss: 25.01700\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1879041/10415869 | Lr: 0.00500 | Smooth loss: 24.68983\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1879041/10415869 | Lr: 0.00500 | Smooth loss: 24.68983\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1910219/10415869 | Lr: 0.00500 | Smooth loss: 24.98053\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1910219/10415869 | Lr: 0.00500 | Smooth loss: 24.98053\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1941032/10415869 | Lr: 0.00500 | Smooth loss: 24.47316\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1941032/10415869 | Lr: 0.00500 | Smooth loss: 24.47316\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1970703/10415869 | Lr: 0.00500 | Smooth loss: 24.59425\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1970703/10415869 | Lr: 0.00500 | Smooth loss: 24.59425\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2001198/10415869 | Lr: 0.00500 | Smooth loss: 24.63356\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2001198/10415869 | Lr: 0.00500 | Smooth loss: 24.63356\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2031817/10415869 | Lr: 0.00500 | Smooth loss: 24.77947\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2031817/10415869 | Lr: 0.00500 | Smooth loss: 24.77947\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2061839/10415869 | Lr: 0.00500 | Smooth loss: 25.58517\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2061839/10415869 | Lr: 0.00500 | Smooth loss: 25.58517\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2091841/10415869 | Lr: 0.00500 | Smooth loss: 24.64248\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2091841/10415869 | Lr: 0.00500 | Smooth loss: 24.64248\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2122848/10415869 | Lr: 0.00500 | Smooth loss: 25.22696\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2122848/10415869 | Lr: 0.00500 | Smooth loss: 25.22696\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2153340/10415869 | Lr: 0.00500 | Smooth loss: 24.12885\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2153340/10415869 | Lr: 0.00500 | Smooth loss: 24.12885\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2184861/10415869 | Lr: 0.00500 | Smooth loss: 24.62168\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2184861/10415869 | Lr: 0.00500 | Smooth loss: 24.62168\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2214598/10415869 | Lr: 0.00500 | Smooth loss: 24.21496\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2214598/10415869 | Lr: 0.00500 | Smooth loss: 24.21496\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2244390/10415869 | Lr: 0.00500 | Smooth loss: 24.68102\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2244390/10415869 | Lr: 0.00500 | Smooth loss: 24.68102\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2275296/10415869 | Lr: 0.00500 | Smooth loss: 24.57656\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2275296/10415869 | Lr: 0.00500 | Smooth loss: 24.57656\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2305883/10415869 | Lr: 0.00500 | Smooth loss: 24.67580\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2305883/10415869 | Lr: 0.00500 | Smooth loss: 24.67580\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2336227/10415869 | Lr: 0.00500 | Smooth loss: 24.47990\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2336227/10415869 | Lr: 0.00500 | Smooth loss: 24.47990\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2366365/10415869 | Lr: 0.00500 | Smooth loss: 23.16723\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2366365/10415869 | Lr: 0.00500 | Smooth loss: 23.16723\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2397945/10415869 | Lr: 0.00500 | Smooth loss: 23.71345\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2397945/10415869 | Lr: 0.00500 | Smooth loss: 23.71345\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2427050/10415869 | Lr: 0.00500 | Smooth loss: 24.04093\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2427050/10415869 | Lr: 0.00500 | Smooth loss: 24.04093\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2458029/10415869 | Lr: 0.00500 | Smooth loss: 24.04450\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2458029/10415869 | Lr: 0.00500 | Smooth loss: 24.04450\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2487667/10415869 | Lr: 0.00500 | Smooth loss: 23.79172\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2487667/10415869 | Lr: 0.00500 | Smooth loss: 23.79172\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2517632/10415869 | Lr: 0.00500 | Smooth loss: 24.18452\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2517632/10415869 | Lr: 0.00500 | Smooth loss: 24.18452\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2547684/10415869 | Lr: 0.00500 | Smooth loss: 23.07684\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2547684/10415869 | Lr: 0.00500 | Smooth loss: 23.07684\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2577003/10415869 | Lr: 0.00500 | Smooth loss: 23.90738\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2577003/10415869 | Lr: 0.00500 | Smooth loss: 23.90738\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2607540/10415869 | Lr: 0.00500 | Smooth loss: 22.84905\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2607540/10415869 | Lr: 0.00500 | Smooth loss: 22.84905\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2636969/10415869 | Lr: 0.00500 | Smooth loss: 24.42365\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2636969/10415869 | Lr: 0.00500 | Smooth loss: 24.42365\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2668087/10415869 | Lr: 0.00500 | Smooth loss: 24.37623\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2668087/10415869 | Lr: 0.00500 | Smooth loss: 24.37623\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2698226/10415869 | Lr: 0.00500 | Smooth loss: 23.78123\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2698226/10415869 | Lr: 0.00500 | Smooth loss: 23.78123\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2729078/10415869 | Lr: 0.00500 | Smooth loss: 23.64558\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2729078/10415869 | Lr: 0.00500 | Smooth loss: 23.64558\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2760069/10415869 | Lr: 0.00500 | Smooth loss: 24.62325\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2760069/10415869 | Lr: 0.00500 | Smooth loss: 24.62325\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2789180/10415869 | Lr: 0.00500 | Smooth loss: 22.90316\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2789180/10415869 | Lr: 0.00500 | Smooth loss: 22.90316\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2818987/10415869 | Lr: 0.00500 | Smooth loss: 23.80472\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2818987/10415869 | Lr: 0.00500 | Smooth loss: 23.80472\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2849703/10415869 | Lr: 0.00500 | Smooth loss: 23.70338\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2849703/10415869 | Lr: 0.00500 | Smooth loss: 23.70338\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2879195/10415869 | Lr: 0.00500 | Smooth loss: 22.89201\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2879195/10415869 | Lr: 0.00500 | Smooth loss: 22.89201\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2908602/10415869 | Lr: 0.00500 | Smooth loss: 23.89073\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2908602/10415869 | Lr: 0.00500 | Smooth loss: 23.89073\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2939752/10415869 | Lr: 0.00500 | Smooth loss: 23.89503\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2939752/10415869 | Lr: 0.00500 | Smooth loss: 23.89503\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2969163/10415869 | Lr: 0.00500 | Smooth loss: 22.84744\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2969163/10415869 | Lr: 0.00500 | Smooth loss: 22.84744\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2998383/10415869 | Lr: 0.00500 | Smooth loss: 22.83895\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2998383/10415869 | Lr: 0.00500 | Smooth loss: 22.83895\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3028086/10415869 | Lr: 0.00500 | Smooth loss: 23.23390\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3028086/10415869 | Lr: 0.00500 | Smooth loss: 23.23390\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3057555/10415869 | Lr: 0.00500 | Smooth loss: 23.06051\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3057555/10415869 | Lr: 0.00500 | Smooth loss: 23.06051\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3086651/10415869 | Lr: 0.00500 | Smooth loss: 24.11949\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3086651/10415869 | Lr: 0.00500 | Smooth loss: 24.11949\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3116963/10415869 | Lr: 0.00500 | Smooth loss: 23.35961\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3116963/10415869 | Lr: 0.00500 | Smooth loss: 23.35961\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3147827/10415869 | Lr: 0.00500 | Smooth loss: 22.99705\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3147827/10415869 | Lr: 0.00500 | Smooth loss: 22.99705\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3177123/10415869 | Lr: 0.00500 | Smooth loss: 21.95434\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3177123/10415869 | Lr: 0.00500 | Smooth loss: 21.95434\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3206844/10415869 | Lr: 0.00500 | Smooth loss: 23.58092\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3206844/10415869 | Lr: 0.00500 | Smooth loss: 23.58092\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3236376/10415869 | Lr: 0.00500 | Smooth loss: 23.42456\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3236376/10415869 | Lr: 0.00500 | Smooth loss: 23.42456\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3266142/10415869 | Lr: 0.00500 | Smooth loss: 22.62358\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3266142/10415869 | Lr: 0.00500 | Smooth loss: 22.62358\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3295829/10415869 | Lr: 0.00500 | Smooth loss: 23.66028\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3295829/10415869 | Lr: 0.00500 | Smooth loss: 23.66028\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3326421/10415869 | Lr: 0.00500 | Smooth loss: 22.38183\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3326421/10415869 | Lr: 0.00500 | Smooth loss: 22.38183\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3357408/10415869 | Lr: 0.00500 | Smooth loss: 22.83063\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3357408/10415869 | Lr: 0.00500 | Smooth loss: 22.83063\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3388126/10415869 | Lr: 0.00500 | Smooth loss: 23.33435\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3388126/10415869 | Lr: 0.00500 | Smooth loss: 23.33435\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3417997/10415869 | Lr: 0.00500 | Smooth loss: 23.19140\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3417997/10415869 | Lr: 0.00500 | Smooth loss: 23.19140\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3448542/10415869 | Lr: 0.00500 | Smooth loss: 23.65698\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3448542/10415869 | Lr: 0.00500 | Smooth loss: 23.65698\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3478427/10415869 | Lr: 0.00500 | Smooth loss: 22.71080\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3478427/10415869 | Lr: 0.00500 | Smooth loss: 22.71080\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3508806/10415869 | Lr: 0.00500 | Smooth loss: 22.55560\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3508806/10415869 | Lr: 0.00500 | Smooth loss: 22.55560\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3539806/10415869 | Lr: 0.00500 | Smooth loss: 22.88453\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3539806/10415869 | Lr: 0.00500 | Smooth loss: 22.88453\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3570289/10415869 | Lr: 0.00500 | Smooth loss: 21.82338\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3570289/10415869 | Lr: 0.00500 | Smooth loss: 21.82338\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3600378/10415869 | Lr: 0.00500 | Smooth loss: 21.93333\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3600378/10415869 | Lr: 0.00500 | Smooth loss: 21.93333\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3630561/10415869 | Lr: 0.00500 | Smooth loss: 22.88582\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3630561/10415869 | Lr: 0.00500 | Smooth loss: 22.88582\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3661159/10415869 | Lr: 0.00500 | Smooth loss: 23.10415\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3661159/10415869 | Lr: 0.00500 | Smooth loss: 23.10415\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3692093/10415869 | Lr: 0.00500 | Smooth loss: 22.78154\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3692093/10415869 | Lr: 0.00500 | Smooth loss: 22.78154\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3723698/10415869 | Lr: 0.00500 | Smooth loss: 22.32922\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3723698/10415869 | Lr: 0.00500 | Smooth loss: 22.32922\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3754339/10415869 | Lr: 0.00500 | Smooth loss: 22.45409\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3754339/10415869 | Lr: 0.00500 | Smooth loss: 22.45409\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3783615/10415869 | Lr: 0.00500 | Smooth loss: 21.86007\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3783615/10415869 | Lr: 0.00500 | Smooth loss: 21.86007\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3813933/10415869 | Lr: 0.00500 | Smooth loss: 22.87902\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3813933/10415869 | Lr: 0.00500 | Smooth loss: 22.87902\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3842944/10415869 | Lr: 0.00500 | Smooth loss: 22.23424\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3842944/10415869 | Lr: 0.00500 | Smooth loss: 22.23424\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3871611/10415869 | Lr: 0.00500 | Smooth loss: 22.42326\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3871611/10415869 | Lr: 0.00500 | Smooth loss: 22.42326\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3902314/10415869 | Lr: 0.00500 | Smooth loss: 23.22427\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3902314/10415869 | Lr: 0.00500 | Smooth loss: 23.22427\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3930770/10415869 | Lr: 0.00500 | Smooth loss: 22.69761\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3930770/10415869 | Lr: 0.00500 | Smooth loss: 22.69761\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3962041/10415869 | Lr: 0.00500 | Smooth loss: 22.22065\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3962041/10415869 | Lr: 0.00500 | Smooth loss: 22.22065\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3993516/10415869 | Lr: 0.00500 | Smooth loss: 22.97974\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3993516/10415869 | Lr: 0.00500 | Smooth loss: 22.97974\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4022746/10415869 | Lr: 0.00500 | Smooth loss: 22.88222\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4022746/10415869 | Lr: 0.00500 | Smooth loss: 22.88222\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4051918/10415869 | Lr: 0.00500 | Smooth loss: 22.16783\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4051918/10415869 | Lr: 0.00500 | Smooth loss: 22.16783\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4082308/10415869 | Lr: 0.00500 | Smooth loss: 21.88019\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4082308/10415869 | Lr: 0.00500 | Smooth loss: 21.88019\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4112549/10415869 | Lr: 0.00500 | Smooth loss: 23.07671\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4112549/10415869 | Lr: 0.00500 | Smooth loss: 23.07671\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4144052/10415869 | Lr: 0.00500 | Smooth loss: 23.10980\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4144052/10415869 | Lr: 0.00500 | Smooth loss: 23.10980\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4174114/10415869 | Lr: 0.00500 | Smooth loss: 22.53801\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4174114/10415869 | Lr: 0.00500 | Smooth loss: 22.53801\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4204842/10415869 | Lr: 0.00500 | Smooth loss: 22.46291\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4204842/10415869 | Lr: 0.00500 | Smooth loss: 22.46291\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4235003/10415869 | Lr: 0.00500 | Smooth loss: 22.17383\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4235003/10415869 | Lr: 0.00500 | Smooth loss: 22.17383\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4265889/10415869 | Lr: 0.00500 | Smooth loss: 22.64791\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4265889/10415869 | Lr: 0.00500 | Smooth loss: 22.64791\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4296017/10415869 | Lr: 0.00500 | Smooth loss: 22.79918\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4296017/10415869 | Lr: 0.00500 | Smooth loss: 22.79918\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4326325/10415869 | Lr: 0.00500 | Smooth loss: 22.17877\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4326325/10415869 | Lr: 0.00500 | Smooth loss: 22.17877\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4356223/10415869 | Lr: 0.00500 | Smooth loss: 22.35345\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4356223/10415869 | Lr: 0.00500 | Smooth loss: 22.35345\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4386318/10415869 | Lr: 0.00500 | Smooth loss: 22.15500\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4386318/10415869 | Lr: 0.00500 | Smooth loss: 22.15500\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4417690/10415869 | Lr: 0.00500 | Smooth loss: 21.73452\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4417690/10415869 | Lr: 0.00500 | Smooth loss: 21.73452\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4448268/10415869 | Lr: 0.00500 | Smooth loss: 21.82221\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4448268/10415869 | Lr: 0.00500 | Smooth loss: 21.82221\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4478785/10415869 | Lr: 0.00500 | Smooth loss: 21.63357\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4478785/10415869 | Lr: 0.00500 | Smooth loss: 21.63357\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4508241/10415869 | Lr: 0.00500 | Smooth loss: 21.85801\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4508241/10415869 | Lr: 0.00500 | Smooth loss: 21.85801\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4538030/10415869 | Lr: 0.00500 | Smooth loss: 22.13417\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4538030/10415869 | Lr: 0.00500 | Smooth loss: 22.13417\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4568305/10415869 | Lr: 0.00500 | Smooth loss: 22.35658\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4568305/10415869 | Lr: 0.00500 | Smooth loss: 22.35658\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4598425/10415869 | Lr: 0.00500 | Smooth loss: 22.59032\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4598425/10415869 | Lr: 0.00500 | Smooth loss: 22.59032\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4628955/10415869 | Lr: 0.00500 | Smooth loss: 22.34030\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4628955/10415869 | Lr: 0.00500 | Smooth loss: 22.34030\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4659364/10415869 | Lr: 0.00500 | Smooth loss: 22.09548\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4659364/10415869 | Lr: 0.00500 | Smooth loss: 22.09548\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4689089/10415869 | Lr: 0.00500 | Smooth loss: 21.33150\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4689089/10415869 | Lr: 0.00500 | Smooth loss: 21.33150\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4720226/10415869 | Lr: 0.00500 | Smooth loss: 22.30180\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4720226/10415869 | Lr: 0.00500 | Smooth loss: 22.30180\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4750522/10415869 | Lr: 0.00500 | Smooth loss: 22.50239\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4750522/10415869 | Lr: 0.00500 | Smooth loss: 22.50239\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4781076/10415869 | Lr: 0.00500 | Smooth loss: 22.70431\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4781076/10415869 | Lr: 0.00500 | Smooth loss: 22.70431\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4812330/10415869 | Lr: 0.00500 | Smooth loss: 22.43085\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4812330/10415869 | Lr: 0.00500 | Smooth loss: 22.43085\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4841687/10415869 | Lr: 0.00500 | Smooth loss: 22.07526\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4841687/10415869 | Lr: 0.00500 | Smooth loss: 22.07526\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4872952/10415869 | Lr: 0.00500 | Smooth loss: 22.21372\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4872952/10415869 | Lr: 0.00500 | Smooth loss: 22.21372\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4903426/10415869 | Lr: 0.00500 | Smooth loss: 21.47666\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4903426/10415869 | Lr: 0.00500 | Smooth loss: 21.47666\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4934240/10415869 | Lr: 0.00500 | Smooth loss: 22.31726\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4934240/10415869 | Lr: 0.00500 | Smooth loss: 22.31726\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4963782/10415869 | Lr: 0.00500 | Smooth loss: 21.98038\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4963782/10415869 | Lr: 0.00500 | Smooth loss: 21.98038\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4993205/10415869 | Lr: 0.00500 | Smooth loss: 21.66623\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4993205/10415869 | Lr: 0.00500 | Smooth loss: 21.66623\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5024080/10415869 | Lr: 0.00500 | Smooth loss: 22.33551\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5024080/10415869 | Lr: 0.00500 | Smooth loss: 22.33551\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5052765/10415869 | Lr: 0.00500 | Smooth loss: 21.50465\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5052765/10415869 | Lr: 0.00500 | Smooth loss: 21.50465\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5083303/10415869 | Lr: 0.00500 | Smooth loss: 21.76540\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5083303/10415869 | Lr: 0.00500 | Smooth loss: 21.76540\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5113152/10415869 | Lr: 0.00500 | Smooth loss: 22.14661\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5113152/10415869 | Lr: 0.00500 | Smooth loss: 22.14661\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5142265/10415869 | Lr: 0.00500 | Smooth loss: 21.96915\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5142265/10415869 | Lr: 0.00500 | Smooth loss: 21.96915\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5172254/10415869 | Lr: 0.00500 | Smooth loss: 21.43607\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5172254/10415869 | Lr: 0.00500 | Smooth loss: 21.43607\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5201780/10415869 | Lr: 0.00500 | Smooth loss: 21.93781\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5201780/10415869 | Lr: 0.00500 | Smooth loss: 21.93781\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5233338/10415869 | Lr: 0.00500 | Smooth loss: 22.28330\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5233338/10415869 | Lr: 0.00500 | Smooth loss: 22.28330\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5263790/10415869 | Lr: 0.00500 | Smooth loss: 21.02860\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5263790/10415869 | Lr: 0.00500 | Smooth loss: 21.02860\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5295072/10415869 | Lr: 0.00500 | Smooth loss: 21.73639\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5295072/10415869 | Lr: 0.00500 | Smooth loss: 21.73639\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5325203/10415869 | Lr: 0.00500 | Smooth loss: 21.54671\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5325203/10415869 | Lr: 0.00500 | Smooth loss: 21.54671\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5355653/10415869 | Lr: 0.00500 | Smooth loss: 21.18699\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5355653/10415869 | Lr: 0.00500 | Smooth loss: 21.18699\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5384411/10415869 | Lr: 0.00500 | Smooth loss: 21.49455\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5384411/10415869 | Lr: 0.00500 | Smooth loss: 21.49455\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5414575/10415869 | Lr: 0.00500 | Smooth loss: 22.31360\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5414575/10415869 | Lr: 0.00500 | Smooth loss: 22.31360\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5445181/10415869 | Lr: 0.00500 | Smooth loss: 21.63392\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5445181/10415869 | Lr: 0.00500 | Smooth loss: 21.63392\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5475038/10415869 | Lr: 0.00500 | Smooth loss: 21.41499\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5475038/10415869 | Lr: 0.00500 | Smooth loss: 21.41499\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5505381/10415869 | Lr: 0.00500 | Smooth loss: 21.67853\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5505381/10415869 | Lr: 0.00500 | Smooth loss: 21.67853\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5536311/10415869 | Lr: 0.00500 | Smooth loss: 20.77965\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5536311/10415869 | Lr: 0.00500 | Smooth loss: 20.77965\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5566352/10415869 | Lr: 0.00500 | Smooth loss: 21.68930\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5566352/10415869 | Lr: 0.00500 | Smooth loss: 21.68930\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5596953/10415869 | Lr: 0.00500 | Smooth loss: 20.71877\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5596953/10415869 | Lr: 0.00500 | Smooth loss: 20.71877\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5627821/10415869 | Lr: 0.00500 | Smooth loss: 21.57710\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5627821/10415869 | Lr: 0.00500 | Smooth loss: 21.57710\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5657989/10415869 | Lr: 0.00500 | Smooth loss: 20.93580\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5657989/10415869 | Lr: 0.00500 | Smooth loss: 20.93580\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5688290/10415869 | Lr: 0.00500 | Smooth loss: 21.59814\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5688290/10415869 | Lr: 0.00500 | Smooth loss: 21.59814\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5718404/10415869 | Lr: 0.00500 | Smooth loss: 21.21242\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5718404/10415869 | Lr: 0.00500 | Smooth loss: 21.21242\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5747952/10415869 | Lr: 0.00500 | Smooth loss: 21.13041\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5747952/10415869 | Lr: 0.00500 | Smooth loss: 21.13041\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5778834/10415869 | Lr: 0.00500 | Smooth loss: 21.07606\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5778834/10415869 | Lr: 0.00500 | Smooth loss: 21.07606\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5809443/10415869 | Lr: 0.00500 | Smooth loss: 20.79882\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5809443/10415869 | Lr: 0.00500 | Smooth loss: 20.79882\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5839369/10415869 | Lr: 0.00500 | Smooth loss: 22.01430\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5839369/10415869 | Lr: 0.00500 | Smooth loss: 22.01430\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5870454/10415869 | Lr: 0.00500 | Smooth loss: 21.21558\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5870454/10415869 | Lr: 0.00500 | Smooth loss: 21.21558\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5900948/10415869 | Lr: 0.00500 | Smooth loss: 21.15443\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5900948/10415869 | Lr: 0.00500 | Smooth loss: 21.15443\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5930687/10415869 | Lr: 0.00500 | Smooth loss: 21.92827\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5930687/10415869 | Lr: 0.00500 | Smooth loss: 21.92827\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5962281/10415869 | Lr: 0.00500 | Smooth loss: 21.16909\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5962281/10415869 | Lr: 0.00500 | Smooth loss: 21.16909\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5993093/10415869 | Lr: 0.00500 | Smooth loss: 21.64651\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5993093/10415869 | Lr: 0.00500 | Smooth loss: 21.64651\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6024212/10415869 | Lr: 0.00500 | Smooth loss: 20.82498\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6024212/10415869 | Lr: 0.00500 | Smooth loss: 20.82498\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6053857/10415869 | Lr: 0.00500 | Smooth loss: 21.58240\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6053857/10415869 | Lr: 0.00500 | Smooth loss: 21.58240\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6084929/10415869 | Lr: 0.00500 | Smooth loss: 22.64726\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6084929/10415869 | Lr: 0.00500 | Smooth loss: 22.64726\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6115715/10415869 | Lr: 0.00500 | Smooth loss: 20.92607\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6115715/10415869 | Lr: 0.00500 | Smooth loss: 20.92607\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6145628/10415869 | Lr: 0.00500 | Smooth loss: 20.93636\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6145628/10415869 | Lr: 0.00500 | Smooth loss: 20.93636\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6175240/10415869 | Lr: 0.00500 | Smooth loss: 21.46771\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6175240/10415869 | Lr: 0.00500 | Smooth loss: 21.46771\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6205998/10415869 | Lr: 0.00500 | Smooth loss: 21.07588\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6205998/10415869 | Lr: 0.00500 | Smooth loss: 21.07588\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6236524/10415869 | Lr: 0.00500 | Smooth loss: 20.79792\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6236524/10415869 | Lr: 0.00500 | Smooth loss: 20.79792\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6267260/10415869 | Lr: 0.00500 | Smooth loss: 21.09009\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6267260/10415869 | Lr: 0.00500 | Smooth loss: 21.09009\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6296647/10415869 | Lr: 0.00500 | Smooth loss: 20.97216\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6296647/10415869 | Lr: 0.00500 | Smooth loss: 20.97216\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6326252/10415869 | Lr: 0.00500 | Smooth loss: 21.79017\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6326252/10415869 | Lr: 0.00500 | Smooth loss: 21.79017\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6357403/10415869 | Lr: 0.00500 | Smooth loss: 21.13003\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6357403/10415869 | Lr: 0.00500 | Smooth loss: 21.13003\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6389066/10415869 | Lr: 0.00500 | Smooth loss: 20.75875\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6389066/10415869 | Lr: 0.00500 | Smooth loss: 20.75875\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6419340/10415869 | Lr: 0.00500 | Smooth loss: 20.96536\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6419340/10415869 | Lr: 0.00500 | Smooth loss: 20.96536\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6450458/10415869 | Lr: 0.00500 | Smooth loss: 21.74904\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6450458/10415869 | Lr: 0.00500 | Smooth loss: 21.74904\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6481196/10415869 | Lr: 0.00500 | Smooth loss: 20.63799\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6481196/10415869 | Lr: 0.00500 | Smooth loss: 20.63799\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6510540/10415869 | Lr: 0.00500 | Smooth loss: 21.35994\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6510540/10415869 | Lr: 0.00500 | Smooth loss: 21.35994\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6539867/10415869 | Lr: 0.00500 | Smooth loss: 20.98589\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6539867/10415869 | Lr: 0.00500 | Smooth loss: 20.98589\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6570361/10415869 | Lr: 0.00500 | Smooth loss: 21.71745\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6570361/10415869 | Lr: 0.00500 | Smooth loss: 21.71745\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6600814/10415869 | Lr: 0.00500 | Smooth loss: 20.80963\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6600814/10415869 | Lr: 0.00500 | Smooth loss: 20.80963\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6630914/10415869 | Lr: 0.00500 | Smooth loss: 20.61437\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6630914/10415869 | Lr: 0.00500 | Smooth loss: 20.61437\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6661728/10415869 | Lr: 0.00500 | Smooth loss: 21.72491\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6661728/10415869 | Lr: 0.00500 | Smooth loss: 21.72491\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6692002/10415869 | Lr: 0.00500 | Smooth loss: 20.70232\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6692002/10415869 | Lr: 0.00500 | Smooth loss: 20.70232\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6722053/10415869 | Lr: 0.00500 | Smooth loss: 20.72575\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6722053/10415869 | Lr: 0.00500 | Smooth loss: 20.72575\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6751982/10415869 | Lr: 0.00500 | Smooth loss: 21.43163\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6751982/10415869 | Lr: 0.00500 | Smooth loss: 21.43163\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6782769/10415869 | Lr: 0.00500 | Smooth loss: 21.35776\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6782769/10415869 | Lr: 0.00500 | Smooth loss: 21.35776\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6812495/10415869 | Lr: 0.00500 | Smooth loss: 20.88028\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6812495/10415869 | Lr: 0.00500 | Smooth loss: 20.88028\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6843272/10415869 | Lr: 0.00500 | Smooth loss: 20.55589\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6843272/10415869 | Lr: 0.00500 | Smooth loss: 20.55589\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6873191/10415869 | Lr: 0.00500 | Smooth loss: 21.26177\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6873191/10415869 | Lr: 0.00500 | Smooth loss: 21.26177\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6903751/10415869 | Lr: 0.00500 | Smooth loss: 21.56431\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6903751/10415869 | Lr: 0.00500 | Smooth loss: 21.56431\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6933297/10415869 | Lr: 0.00500 | Smooth loss: 20.56761\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6933297/10415869 | Lr: 0.00500 | Smooth loss: 20.56761\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6964651/10415869 | Lr: 0.00500 | Smooth loss: 21.52194\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6964651/10415869 | Lr: 0.00500 | Smooth loss: 21.52194\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6994234/10415869 | Lr: 0.00500 | Smooth loss: 20.48481\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6994234/10415869 | Lr: 0.00500 | Smooth loss: 20.48481\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7023729/10415869 | Lr: 0.00500 | Smooth loss: 21.11966\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7023729/10415869 | Lr: 0.00500 | Smooth loss: 21.11966\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7054652/10415869 | Lr: 0.00500 | Smooth loss: 21.90013\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7054652/10415869 | Lr: 0.00500 | Smooth loss: 21.90013\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7085376/10415869 | Lr: 0.00500 | Smooth loss: 21.13224\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7085376/10415869 | Lr: 0.00500 | Smooth loss: 21.13224\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7115661/10415869 | Lr: 0.00500 | Smooth loss: 21.65738\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7115661/10415869 | Lr: 0.00500 | Smooth loss: 21.65738\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7145620/10415869 | Lr: 0.00500 | Smooth loss: 21.05343\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7145620/10415869 | Lr: 0.00500 | Smooth loss: 21.05343\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7176309/10415869 | Lr: 0.00500 | Smooth loss: 20.46359\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7176309/10415869 | Lr: 0.00500 | Smooth loss: 20.46359\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7207362/10415869 | Lr: 0.00500 | Smooth loss: 20.87885\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7207362/10415869 | Lr: 0.00500 | Smooth loss: 20.87885\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7237073/10415869 | Lr: 0.00500 | Smooth loss: 20.81695\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7237073/10415869 | Lr: 0.00500 | Smooth loss: 20.81695\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7268071/10415869 | Lr: 0.00500 | Smooth loss: 20.98517\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7268071/10415869 | Lr: 0.00500 | Smooth loss: 20.98517\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7298417/10415869 | Lr: 0.00500 | Smooth loss: 20.09130\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7298417/10415869 | Lr: 0.00500 | Smooth loss: 20.09130\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7328048/10415869 | Lr: 0.00500 | Smooth loss: 19.79383\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7328048/10415869 | Lr: 0.00500 | Smooth loss: 19.79383\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7358492/10415869 | Lr: 0.00500 | Smooth loss: 20.81647\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7358492/10415869 | Lr: 0.00500 | Smooth loss: 20.81647\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7389557/10415869 | Lr: 0.00500 | Smooth loss: 20.78023\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7389557/10415869 | Lr: 0.00500 | Smooth loss: 20.78023\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7418052/10415869 | Lr: 0.00500 | Smooth loss: 20.06381\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7418052/10415869 | Lr: 0.00500 | Smooth loss: 20.06381\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7448201/10415869 | Lr: 0.00500 | Smooth loss: 21.19112\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7448201/10415869 | Lr: 0.00500 | Smooth loss: 21.19112\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7477328/10415869 | Lr: 0.00500 | Smooth loss: 20.29376\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7477328/10415869 | Lr: 0.00500 | Smooth loss: 20.29376\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7508236/10415869 | Lr: 0.00500 | Smooth loss: 20.47196\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7508236/10415869 | Lr: 0.00500 | Smooth loss: 20.47196\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7538005/10415869 | Lr: 0.00500 | Smooth loss: 20.54559\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7538005/10415869 | Lr: 0.00500 | Smooth loss: 20.54559\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7568515/10415869 | Lr: 0.00500 | Smooth loss: 20.20855\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7568515/10415869 | Lr: 0.00500 | Smooth loss: 20.20855\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7598198/10415869 | Lr: 0.00500 | Smooth loss: 20.61236\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7598198/10415869 | Lr: 0.00500 | Smooth loss: 20.61236\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7627506/10415869 | Lr: 0.00500 | Smooth loss: 20.25563\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7627506/10415869 | Lr: 0.00500 | Smooth loss: 20.25563\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7657848/10415869 | Lr: 0.00500 | Smooth loss: 20.16947\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7657848/10415869 | Lr: 0.00500 | Smooth loss: 20.16947\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7688055/10415869 | Lr: 0.00500 | Smooth loss: 20.50100\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7688055/10415869 | Lr: 0.00500 | Smooth loss: 20.50100\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7717907/10415869 | Lr: 0.00500 | Smooth loss: 20.18653\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7717907/10415869 | Lr: 0.00500 | Smooth loss: 20.18653\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7748792/10415869 | Lr: 0.00500 | Smooth loss: 19.97132\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7748792/10415869 | Lr: 0.00500 | Smooth loss: 19.97132\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7778072/10415869 | Lr: 0.00500 | Smooth loss: 20.41849\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7778072/10415869 | Lr: 0.00500 | Smooth loss: 20.41849\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7807719/10415869 | Lr: 0.00500 | Smooth loss: 20.77304\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7807719/10415869 | Lr: 0.00500 | Smooth loss: 20.77304\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7837203/10415869 | Lr: 0.00500 | Smooth loss: 20.09255\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7837203/10415869 | Lr: 0.00500 | Smooth loss: 20.09255\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7868722/10415869 | Lr: 0.00500 | Smooth loss: 20.52350\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7868722/10415869 | Lr: 0.00500 | Smooth loss: 20.52350\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7897925/10415869 | Lr: 0.00500 | Smooth loss: 19.87707\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7897925/10415869 | Lr: 0.00500 | Smooth loss: 19.87707\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7928020/10415869 | Lr: 0.00500 | Smooth loss: 19.38647\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7928020/10415869 | Lr: 0.00500 | Smooth loss: 19.38647\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7959457/10415869 | Lr: 0.00500 | Smooth loss: 20.68580\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7959457/10415869 | Lr: 0.00500 | Smooth loss: 20.68580\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7989482/10415869 | Lr: 0.00500 | Smooth loss: 20.59969\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7989482/10415869 | Lr: 0.00500 | Smooth loss: 20.59969\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8019349/10415869 | Lr: 0.00500 | Smooth loss: 20.19259\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8019349/10415869 | Lr: 0.00500 | Smooth loss: 20.19259\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8050270/10415869 | Lr: 0.00500 | Smooth loss: 20.37924\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8050270/10415869 | Lr: 0.00500 | Smooth loss: 20.37924\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8080261/10415869 | Lr: 0.00500 | Smooth loss: 20.45844\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8080261/10415869 | Lr: 0.00500 | Smooth loss: 20.45844\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8110761/10415869 | Lr: 0.00500 | Smooth loss: 20.14654\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8110761/10415869 | Lr: 0.00500 | Smooth loss: 20.14654\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8140689/10415869 | Lr: 0.00500 | Smooth loss: 19.85953\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8140689/10415869 | Lr: 0.00500 | Smooth loss: 19.85953\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8171418/10415869 | Lr: 0.00500 | Smooth loss: 19.45351\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8171418/10415869 | Lr: 0.00500 | Smooth loss: 19.45351\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8201032/10415869 | Lr: 0.00500 | Smooth loss: 20.88422\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8201032/10415869 | Lr: 0.00500 | Smooth loss: 20.88422\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8230531/10415869 | Lr: 0.00500 | Smooth loss: 20.63223\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8230531/10415869 | Lr: 0.00500 | Smooth loss: 20.63223\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8261230/10415869 | Lr: 0.00500 | Smooth loss: 20.82207\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8261230/10415869 | Lr: 0.00500 | Smooth loss: 20.82207\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8291511/10415869 | Lr: 0.00500 | Smooth loss: 20.60661\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8291511/10415869 | Lr: 0.00500 | Smooth loss: 20.60661\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8322072/10415869 | Lr: 0.00500 | Smooth loss: 20.15031\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8322072/10415869 | Lr: 0.00500 | Smooth loss: 20.15031\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8351877/10415869 | Lr: 0.00500 | Smooth loss: 19.78868\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8351877/10415869 | Lr: 0.00500 | Smooth loss: 19.78868\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8381851/10415869 | Lr: 0.00500 | Smooth loss: 19.95907\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8381851/10415869 | Lr: 0.00500 | Smooth loss: 19.95907\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8412692/10415869 | Lr: 0.00500 | Smooth loss: 20.33453\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8412692/10415869 | Lr: 0.00500 | Smooth loss: 20.33453\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8443718/10415869 | Lr: 0.00500 | Smooth loss: 20.40900\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8443718/10415869 | Lr: 0.00500 | Smooth loss: 20.40900\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8473179/10415869 | Lr: 0.00500 | Smooth loss: 19.67584\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8473179/10415869 | Lr: 0.00500 | Smooth loss: 19.67584\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8504859/10415869 | Lr: 0.00500 | Smooth loss: 20.78156\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8504859/10415869 | Lr: 0.00500 | Smooth loss: 20.78156\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8535730/10415869 | Lr: 0.00500 | Smooth loss: 20.58192\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8535730/10415869 | Lr: 0.00500 | Smooth loss: 20.58192\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8566080/10415869 | Lr: 0.00500 | Smooth loss: 20.14985\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8566080/10415869 | Lr: 0.00500 | Smooth loss: 20.14985\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8596857/10415869 | Lr: 0.00500 | Smooth loss: 19.84943\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8596857/10415869 | Lr: 0.00500 | Smooth loss: 19.84943\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8625565/10415869 | Lr: 0.00500 | Smooth loss: 19.50994\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8625565/10415869 | Lr: 0.00500 | Smooth loss: 19.50994\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8656506/10415869 | Lr: 0.00500 | Smooth loss: 20.35957\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8656506/10415869 | Lr: 0.00500 | Smooth loss: 20.35957\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8686246/10415869 | Lr: 0.00500 | Smooth loss: 19.52171\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8686246/10415869 | Lr: 0.00500 | Smooth loss: 19.52171\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8715008/10415869 | Lr: 0.00500 | Smooth loss: 19.91123\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8715008/10415869 | Lr: 0.00500 | Smooth loss: 19.91123\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8746013/10415869 | Lr: 0.00500 | Smooth loss: 20.10898\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8746013/10415869 | Lr: 0.00500 | Smooth loss: 20.10898\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8777021/10415869 | Lr: 0.00500 | Smooth loss: 20.00813\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8777021/10415869 | Lr: 0.00500 | Smooth loss: 20.00813\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8806984/10415869 | Lr: 0.00500 | Smooth loss: 19.88700\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8806984/10415869 | Lr: 0.00500 | Smooth loss: 19.88700\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8837094/10415869 | Lr: 0.00500 | Smooth loss: 20.06564\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8837094/10415869 | Lr: 0.00500 | Smooth loss: 20.06564\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8866874/10415869 | Lr: 0.00500 | Smooth loss: 19.55815\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8866874/10415869 | Lr: 0.00500 | Smooth loss: 19.55815\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8897051/10415869 | Lr: 0.00500 | Smooth loss: 20.34148\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8897051/10415869 | Lr: 0.00500 | Smooth loss: 20.34148\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8928387/10415869 | Lr: 0.00500 | Smooth loss: 20.39512\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8928387/10415869 | Lr: 0.00500 | Smooth loss: 20.39512\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8959133/10415869 | Lr: 0.00500 | Smooth loss: 19.89021\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8959133/10415869 | Lr: 0.00500 | Smooth loss: 19.89021\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8989020/10415869 | Lr: 0.00500 | Smooth loss: 19.79133\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8989020/10415869 | Lr: 0.00500 | Smooth loss: 19.79133\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9018726/10415869 | Lr: 0.00500 | Smooth loss: 19.56596\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9018726/10415869 | Lr: 0.00500 | Smooth loss: 19.56596\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9049447/10415869 | Lr: 0.00500 | Smooth loss: 20.12208\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9049447/10415869 | Lr: 0.00500 | Smooth loss: 20.12208\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9080791/10415869 | Lr: 0.00500 | Smooth loss: 20.30149\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9080791/10415869 | Lr: 0.00500 | Smooth loss: 20.30149\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9110118/10415869 | Lr: 0.00500 | Smooth loss: 19.19468\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9110118/10415869 | Lr: 0.00500 | Smooth loss: 19.19468\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9140656/10415869 | Lr: 0.00500 | Smooth loss: 19.66112\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9140656/10415869 | Lr: 0.00500 | Smooth loss: 19.66112\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9171045/10415869 | Lr: 0.00500 | Smooth loss: 20.35633\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9171045/10415869 | Lr: 0.00500 | Smooth loss: 20.35633\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9202417/10415869 | Lr: 0.00500 | Smooth loss: 20.14894\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9202417/10415869 | Lr: 0.00500 | Smooth loss: 20.14894\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9231643/10415869 | Lr: 0.00500 | Smooth loss: 19.87861\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9231643/10415869 | Lr: 0.00500 | Smooth loss: 19.87861\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9261245/10415869 | Lr: 0.00500 | Smooth loss: 19.80146\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9261245/10415869 | Lr: 0.00500 | Smooth loss: 19.80146\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9290369/10415869 | Lr: 0.00500 | Smooth loss: 19.09792\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9290369/10415869 | Lr: 0.00500 | Smooth loss: 19.09792\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9321889/10415869 | Lr: 0.00500 | Smooth loss: 19.96810\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9321889/10415869 | Lr: 0.00500 | Smooth loss: 19.96810\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9352183/10415869 | Lr: 0.00500 | Smooth loss: 19.59202\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9352183/10415869 | Lr: 0.00500 | Smooth loss: 19.59202\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9382506/10415869 | Lr: 0.00500 | Smooth loss: 19.25046\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9382506/10415869 | Lr: 0.00500 | Smooth loss: 19.25046\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9414163/10415869 | Lr: 0.00500 | Smooth loss: 19.77557\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9414163/10415869 | Lr: 0.00500 | Smooth loss: 19.77557\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9445351/10415869 | Lr: 0.00500 | Smooth loss: 19.49921\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9445351/10415869 | Lr: 0.00500 | Smooth loss: 19.49921\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9475228/10415869 | Lr: 0.00500 | Smooth loss: 20.11860\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9475228/10415869 | Lr: 0.00500 | Smooth loss: 20.11860\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9505930/10415869 | Lr: 0.00500 | Smooth loss: 19.26137\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9505930/10415869 | Lr: 0.00500 | Smooth loss: 19.26137\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9536912/10415869 | Lr: 0.00500 | Smooth loss: 19.25539\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9536912/10415869 | Lr: 0.00500 | Smooth loss: 19.25539\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9568486/10415869 | Lr: 0.00500 | Smooth loss: 19.24179\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9568486/10415869 | Lr: 0.00500 | Smooth loss: 19.24179\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9598370/10415869 | Lr: 0.00500 | Smooth loss: 19.87654\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9598370/10415869 | Lr: 0.00500 | Smooth loss: 19.87654\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9629628/10415869 | Lr: 0.00500 | Smooth loss: 19.96786\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9629628/10415869 | Lr: 0.00500 | Smooth loss: 19.96786\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9659034/10415869 | Lr: 0.00500 | Smooth loss: 19.31624\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9659034/10415869 | Lr: 0.00500 | Smooth loss: 19.31624\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9688787/10415869 | Lr: 0.00500 | Smooth loss: 19.40947\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9688787/10415869 | Lr: 0.00500 | Smooth loss: 19.40947\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9719648/10415869 | Lr: 0.00500 | Smooth loss: 19.49820\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9719648/10415869 | Lr: 0.00500 | Smooth loss: 19.49820\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9748665/10415869 | Lr: 0.00500 | Smooth loss: 19.34174\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9748665/10415869 | Lr: 0.00500 | Smooth loss: 19.34174\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9779672/10415869 | Lr: 0.00500 | Smooth loss: 19.73519\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9779672/10415869 | Lr: 0.00500 | Smooth loss: 19.73519\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9809874/10415869 | Lr: 0.00500 | Smooth loss: 19.49591\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9809874/10415869 | Lr: 0.00500 | Smooth loss: 19.49591\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9839095/10415869 | Lr: 0.00500 | Smooth loss: 18.91791\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9839095/10415869 | Lr: 0.00500 | Smooth loss: 18.91791\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9868953/10415869 | Lr: 0.00500 | Smooth loss: 19.30897\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9868953/10415869 | Lr: 0.00500 | Smooth loss: 19.30897\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9898861/10415869 | Lr: 0.00500 | Smooth loss: 18.93859\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9898861/10415869 | Lr: 0.00500 | Smooth loss: 18.93859\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9928849/10415869 | Lr: 0.00500 | Smooth loss: 19.69851\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9928849/10415869 | Lr: 0.00500 | Smooth loss: 19.69851\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9959675/10415869 | Lr: 0.00500 | Smooth loss: 19.60168\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9959675/10415869 | Lr: 0.00500 | Smooth loss: 19.60168\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9989882/10415869 | Lr: 0.00500 | Smooth loss: 19.74507\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9989882/10415869 | Lr: 0.00500 | Smooth loss: 19.74507\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 10020265/10415869 | Lr: 0.00500 | Smooth loss: 19.14217\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 10020265/10415869 | Lr: 0.00500 | Smooth loss: 19.14217\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 10051853/10415869 | Lr: 0.00500 | Smooth loss: 20.06260\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 10051853/10415869 | Lr: 0.00500 | Smooth loss: 20.06260\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 10081426/10415869 | Lr: 0.00500 | Smooth loss: 19.87331\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 10081426/10415869 | Lr: 0.00500 | Smooth loss: 19.87331\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 10111647/10415869 | Lr: 0.00500 | Smooth loss: 19.33447\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 10111647/10415869 | Lr: 0.00500 | Smooth loss: 19.33447\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 10141950/10415869 | Lr: 0.00500 | Smooth loss: 19.88320\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 10141950/10415869 | Lr: 0.00500 | Smooth loss: 19.88320\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 10172811/10415869 | Lr: 0.00500 | Smooth loss: 19.55613\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 10172811/10415869 | Lr: 0.00500 | Smooth loss: 19.55613\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 10202819/10415869 | Lr: 0.00500 | Smooth loss: 19.02627\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 10202819/10415869 | Lr: 0.00500 | Smooth loss: 19.02627\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 10233567/10415869 | Lr: 0.00500 | Smooth loss: 19.53694\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 10233567/10415869 | Lr: 0.00500 | Smooth loss: 19.53694\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 10264426/10415869 | Lr: 0.00500 | Smooth loss: 19.64486\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 10264426/10415869 | Lr: 0.00500 | Smooth loss: 19.64486\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 10294709/10415869 | Lr: 0.00500 | Smooth loss: 19.62175\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 10294709/10415869 | Lr: 0.00500 | Smooth loss: 19.62175\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 10325697/10415869 | Lr: 0.00500 | Smooth loss: 19.23110\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 10325697/10415869 | Lr: 0.00500 | Smooth loss: 19.23110\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 10355567/10415869 | Lr: 0.00500 | Smooth loss: 19.33120\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 10355567/10415869 | Lr: 0.00500 | Smooth loss: 19.33120\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 10386582/10415869 | Lr: 0.00500 | Smooth loss: 19.74460\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 10386582/10415869 | Lr: 0.00500 | Smooth loss: 19.74460\n"]},{"output_type":"stream","name":"stdout","text":["Load embeddings ./tmp/Challenge_Dataset/train_transe_model/transe_model_sd_epoch_1.ckpt\n"]}],"source":["logger = None\n","convergence = 0\n","smooth_loss_min = 0\n","\n","\n","def train(dataset='challenge',name='train_transe_model',log_dir = './', device='cuda',seed=123,gpu='0',epochs=1, batch_size=64,lr=0.5,weight_decay=0,l2_lambda=0,max_grad_norm=5.0,embed_size=300,num_neg_samples=5,steps_per_checkpoint=200):\n","    data = load_dataset(dataset)\n","    dataloader = ChallengeDataLoader(data, batch_size)\n","    words_to_train = epochs * data.text.word_count + 1\n","\n","    model = KnowledgeEmbedding(data, device=device,seed=123,gpu='0',epochs=1, batch_size=64,lr=0.5,weight_decay=0,l2_lambda=0,max_grad_norm=5.0,embed_size=300,num_neg_samples=5,steps_per_checkpoint=200).to(device)\n","     #logger.info('Parameters:' + str([i[0] for i in model.named_parameters()]))\n","    optimizer = optim.SGD(model.parameters(), lr=lr)\n","    steps = 0\n","    smooth_loss = 0.0\n","\n","    for epoch in range(1, epochs + 1):\n","        dataloader.reset()\n","        while dataloader.has_next():\n","            # Set learning rate.\n","            #lr = lr * max(1e-4, 1.0 - dataloader.finished_word_num / float(words_to_train))\n","            for pg in optimizer.param_groups:\n","                pg['lr'] = lr\n","\n","            # Get training batch.\n","            batch_idxs = dataloader.get_batch()\n","            batch_idxs = torch.from_numpy(batch_idxs).to(device)\n","\n","            # Train model.\n","            optimizer.zero_grad()\n","            train_loss = model(batch_idxs)\n","            train_loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n","            optimizer.step()\n","            smooth_loss += train_loss.item() / steps_per_checkpoint\n","\n","            steps += 1\n","            if steps % steps_per_checkpoint == 0:\n","                logger.info('Epoch: {:02d} | '.format(epoch) +\n","                            'Words: {:d}/{:d} | '.format(dataloader.finished_word_num, words_to_train) +\n","                            'Lr: {:.5f} | '.format(lr) +\n","                            'Smooth loss: {:.5f}'.format(smooth_loss))\n","                smooth_loss = 0.0\n","\n","        torch.save(model.state_dict(), '{}/transe_model_sd_epoch_{}.ckpt'.format(log_dir, epoch))\n","\n","\n","def extract_embeddings(dataset='challenge',name='train_transe_model',log_dir='./', seed=123,gpu='0',epochs=1, batch_size=64,lr=0.5,weight_decay=0,l2_lambda=0,max_grad_norm=5.0,embed_size=300,num_neg_samples=5,steps_per_checkpoint=200):\n","    \"\"\"Note that last entity embedding is of size [vocab_size+1, d].\"\"\"\n","    model_file = '{}/transe_model_sd_epoch_{}.ckpt'.format(log_dir, epochs)\n","    print('Load embeddings', model_file)\n","    state_dict = torch.load(model_file, map_location=lambda storage, loc: storage)\n","    embeds = {\n","        USER: state_dict['user.weight'].cpu().data.numpy()[:-1],  # Must remove last dummy 'user' with 0 embed.\n","        ARTICLE: state_dict['article.weight'].cpu().data.numpy()[:-1],\n","        WORD: state_dict['word.weight'].cpu().data.numpy()[:-1],\n","        TOPIC: state_dict['topic.weight'].cpu().data.numpy()[:-1],\n","        PRODUCT: state_dict['product.weight'].cpu().data.numpy()[:-1],\n","        RARTICLE: state_dict['related_article.weight'].cpu().data.numpy()[:-1],\n","        TOPIC_TAG: state_dict['topic_tag.weight'].cpu().data.numpy()[:-1],\n","        PRODUCT_TAG: state_dict['product_tag.weight'].cpu().data.numpy()[:-1],\n","\n","        RECOMMENDED: (\n","            state_dict['recommended'].cpu().data.numpy()[0],\n","            state_dict['recommended_bias.weight'].cpu().data.numpy()\n","        ),\n","        WITHIN: (\n","            state_dict['within'].cpu().data.numpy()[0],\n","            state_dict['within_bias.weight'].cpu().data.numpy()\n","        ),\n","        HAS_TOPIC: (\n","            state_dict['has_topic'].cpu().data.numpy()[0],\n","            state_dict['has_topic_bias.weight'].cpu().data.numpy()\n","        ),\n","        HAS_PRODUCT: (\n","            state_dict['has_product'].cpu().data.numpy()[0],\n","            state_dict['has_product_bias.weight'].cpu().data.numpy()\n","        ),\n","        HAS_TOPIC_TAG: (\n","            state_dict['has_topic_tag'].cpu().data.numpy()[0],\n","            state_dict['has_topic_tag_bias.weight'].cpu().data.numpy()\n","        ),\n","        HAS_PRODUCT_TAG: (\n","            state_dict['has_product_tag'].cpu().data.numpy()[0],\n","            state_dict['has_product_tag_bias.weight'].cpu().data.numpy()\n","        ),\n","        ALSO_RESPONSE: (\n","            state_dict['also_response'].cpu().data.numpy()[0],\n","            state_dict['also_response_bias.weight'].cpu().data.numpy()\n","        ),\n","        RECOMMENDED_TOGETHER: (\n","            state_dict['recommended_together'].cpu().data.numpy()[0],\n","            state_dict['recommended_together_bias.weight'].cpu().data.numpy()\n","        ),\n","        RESPONSE_TOGETHER: (\n","            state_dict['response_together'].cpu().data.numpy()[0],\n","            state_dict['response_together_bias.weight'].cpu().data.numpy()\n","        ),\n","    }\n","    save_embed(dataset, embeds)\n","\n","\n","def main(dataset='challenge',name='train_transe_model',seed=123,gpu='0',epochs=1, batch_size=64,lr=0.5,weight_decay=0,l2_lambda=0,max_grad_norm=5.0,embed_size=300,num_neg_samples=5,steps_per_checkpoint=200):\n","\n","    os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n","    device = torch.device('cuda:0') if torch.cuda.is_available() else 'cpu'\n","\n","    log_dir = '{}/{}'.format(TMP_DIR[dataset], name)\n","    print(log_dir)\n","    if not os.path.isdir(log_dir):\n","        os.makedirs(log_dir)\n","\n","    global logger\n","    logger = get_logger(log_dir + '/train_log.txt')\n","    set_random_seed(seed)\n","    train(dataset='challenge',name='train_transe_model',log_dir= '{}/{}'.format(TMP_DIR[dataset], name),device=device,seed=123,gpu='0',epochs=1, batch_size=64,lr=0.005,weight_decay=0,l2_lambda=0,max_grad_norm=5.0,embed_size=300,num_neg_samples=5,steps_per_checkpoint=200)\n","    extract_embeddings(dataset='challenge',name='train_transe_model',log_dir=log_dir, seed=123,gpu='0',epochs=1, batch_size=64,lr=0.005,weight_decay=0,l2_lambda=0,max_grad_norm=5.0,embed_size=300,num_neg_samples=5,steps_per_checkpoint=200)\n","\n","\n","if __name__ == '__main__':\n","    main(dataset='challenge',name='train_transe_model',seed=123,gpu='0',epochs=1, batch_size=64,lr=0.005,weight_decay=0,l2_lambda=0,max_grad_norm=5.0,embed_size=300,num_neg_samples=5,steps_per_checkpoint=200)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZEr-pltWnF41"},"outputs":[],"source":["import argparse\n","from collections import namedtuple\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.autograd import Variable\n","from torch.distributions import Categorical\n","\n","from kg_env import BatchKGEnvironment"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nawYuQv1nF42","executionInfo":{"status":"ok","timestamp":1689936461743,"user_tz":-60,"elapsed":2038,"user":{"displayName":"huan chen","userId":"01704466685251061733"}},"outputId":"03e37d32-ee96-4c15-cd83-13122d3c7921"},"outputs":[{"output_type":"stream","name":"stdout","text":["Load embedding: ./tmp/Challenge_Dataset/transe_embed.pkl\n","[INFO]  Parameters:['l1.weight', 'l1.bias', 'l2.weight', 'l2.bias', 'actor.weight', 'actor.bias', 'critic.weight', 'critic.bias']\n","[INFO]  Parameters:['l1.weight', 'l1.bias', 'l2.weight', 'l2.bias', 'actor.weight', 'actor.bias', 'critic.weight', 'critic.bias']\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_agent/train_log.txt:Parameters:['l1.weight', 'l1.bias', 'l2.weight', 'l2.bias', 'actor.weight', 'actor.bias', 'critic.weight', 'critic.bias']\n","<ipython-input-17-f55a25594160>:29: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at ../aten/src/ATen/native/cuda/Indexing.cu:1440.)\n","  actor_logits[1 - act_mask] = -999999.0\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Save model to ./tmp/Challenge_Dataset/train_agent/policy_model_epoch_1.ckpt\n","[INFO]  Save model to ./tmp/Challenge_Dataset/train_agent/policy_model_epoch_1.ckpt\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_agent/train_log.txt:Save model to ./tmp/Challenge_Dataset/train_agent/policy_model_epoch_1.ckpt\n"]}],"source":["logger = None\n","\n","SavedAction = namedtuple('SavedAction', ['log_prob', 'value'])\n","\n","class ActorCritic(nn.Module):\n","    def __init__(self, state_dim, act_dim, gamma=0.99, hidden_sizes=[512, 256]):\n","        super(ActorCritic, self).__init__()\n","        self.state_dim = state_dim\n","        self.act_dim = act_dim\n","        self.gamma = gamma\n","\n","        self.l1 = nn.Linear(state_dim, hidden_sizes[0])\n","        self.l2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n","        self.actor = nn.Linear(hidden_sizes[1], act_dim)\n","        self.critic = nn.Linear(hidden_sizes[1], 1)\n","\n","        self.saved_actions = []\n","        self.rewards = []\n","        self.entropy = []\n","\n","    def forward(self, inputs):\n","        state, act_mask = inputs  # state: [bs, state_dim], act_mask: [bs, act_dim]\n","        x = self.l1(state)\n","        x = F.dropout(F.elu(x), p=0.5)\n","        out = self.l2(x)\n","        x = F.dropout(F.elu(out), p=0.5)\n","\n","        actor_logits = self.actor(x)\n","        actor_logits[1 - act_mask] = -999999.0\n","        act_probs = F.softmax(actor_logits, dim=-1)  # Tensor of [bs, act_dim]\n","\n","        state_values = self.critic(x)  # Tensor of [bs, 1]\n","        return act_probs, state_values\n","\n","    def select_action(self, batch_state, batch_act_mask, device):\n","        state = torch.FloatTensor(batch_state).to(device)  # Tensor [bs, state_dim]\n","        act_mask = torch.ByteTensor(batch_act_mask).to(device)  # Tensor of [bs, act_dim]\n","\n","        probs, value = self((state, act_mask))  # act_probs: [bs, act_dim], state_value: [bs, 1]\n","        m = Categorical(probs)\n","        acts = m.sample()  # Tensor of [bs, ], requires_grad=False\n","        # [CAVEAT] If sampled action is out of action_space, choose the first action in action_space.\n","        valid_idx = act_mask.gather(1, acts.view(-1, 1)).view(-1)\n","        acts[valid_idx == 0] = 0\n","\n","        self.saved_actions.append(SavedAction(m.log_prob(acts), value))\n","        self.entropy.append(m.entropy())\n","        return acts.cpu().numpy().tolist()\n","\n","    def update(self, optimizer, device, ent_weight):\n","        if len(self.rewards) <= 0:\n","            del self.rewards[:]\n","            del self.saved_actions[:]\n","            del self.entropy[:]\n","            return 0.0, 0.0, 0.0\n","\n","        batch_rewards = np.vstack(self.rewards).T  # numpy array of [bs, #steps]\n","        batch_rewards = torch.FloatTensor(batch_rewards).to(device)\n","        num_steps = batch_rewards.shape[1]\n","        for i in range(1, num_steps):\n","            batch_rewards[:, num_steps - i - 1] += self.gamma * batch_rewards[:, num_steps - i]\n","\n","        actor_loss = 0\n","        critic_loss = 0\n","        entropy_loss = 0\n","        for i in range(0, num_steps):\n","            log_prob, value = self.saved_actions[i]  # log_prob: Tensor of [bs, ], value: Tensor of [bs, 1]\n","            advantage = batch_rewards[:, i] - value.squeeze(1)  # Tensor of [bs, ]\n","            actor_loss += -log_prob * advantage.detach()  # Tensor of [bs, ]\n","            critic_loss += advantage.pow(2)  # Tensor of [bs, ]\n","            entropy_loss += -self.entropy[i]  # Tensor of [bs, ]\n","        actor_loss = actor_loss.mean()\n","        critic_loss = critic_loss.mean()\n","        entropy_loss = entropy_loss.mean()\n","        loss = actor_loss + critic_loss + ent_weight * entropy_loss\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        del self.rewards[:]\n","        del self.saved_actions[:]\n","        del self.entropy[:]\n","\n","        return loss.item(), actor_loss.item(), critic_loss.item(), entropy_loss.item()\n","\n","\n","class ACDataLoader(object):\n","    def __init__(self, uids, batch_size):\n","        self.uids = np.array(uids)\n","        self.num_users = len(uids)\n","        self.batch_size = batch_size\n","        self.reset()\n","\n","    def reset(self):\n","        self._rand_perm = np.random.permutation(self.num_users)\n","        self._start_idx = 0\n","        self._has_next = True\n","\n","    def has_next(self):\n","        return self._has_next\n","\n","    def get_batch(self):\n","        if not self._has_next:\n","            return None\n","        # Multiple users per batch\n","        end_idx = min(self._start_idx + self.batch_size, self.num_users)\n","        batch_idx = self._rand_perm[self._start_idx:end_idx]\n","        batch_uids = self.uids[batch_idx]\n","        self._has_next = self._has_next and end_idx < self.num_users\n","        self._start_idx = end_idx\n","        return batch_uids.tolist()\n","\n","\n","def train( dataset='challenge',name='train_agent',seed=123,gpu='0',epochs=1, batch_size=32,lr=1e-4,max_acts=250,max_path_len=3,\n","    gamma=0.99,ent_weight=1e-3,act_dropout=0.5,state_history=1,hidden=[512, 256],device='cuda',log_dir='./'):\n","    env = BatchKGEnvironment(dataset, max_acts, max_path_len=max_path_len, state_history=state_history)\n","    uids = list(env.kg(USER).keys())\n","    dataloader = ACDataLoader(uids, batch_size)\n","    model = ActorCritic(env.state_dim, env.act_dim, gamma=gamma, hidden_sizes=hidden).to(device)\n","    logger.info('Parameters:' + str([i[0] for i in model.named_parameters()]))\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","\n","    total_losses, total_plosses, total_vlosses, total_entropy, total_rewards = [], [], [], [], []\n","    step = 0\n","    model.train()\n","    for epoch in range(1, epochs + 1):\n","        ### Start epoch ###\n","        dataloader.reset()\n","        while dataloader.has_next():\n","            batch_uids = dataloader.get_batch()\n","            ### Start batch episodes ###\n","            batch_state = env.reset(batch_uids)  # numpy array of [bs, state_dim]\n","            done = False\n","            while not done:\n","                batch_act_mask = env.batch_action_mask(dropout=act_dropout)  # numpy array of size [bs, act_dim]\n","                batch_act_idx = model.select_action(batch_state, batch_act_mask, device)  # int\n","                batch_state, batch_reward, done = env.batch_step(batch_act_idx)\n","                model.rewards.append(batch_reward)\n","            ### End of episodes ###\n","\n","            lr_e = lr * max(1e-4, 1.0 - float(step) / (epochs * len(uids) / batch_size))\n","            for pg in optimizer.param_groups:\n","                pg['lr'] = lr_e\n","\n","            # Update policy\n","            total_rewards.append(np.sum(model.rewards))\n","            loss, ploss, vloss, eloss = model.update(optimizer, device, ent_weight)\n","            total_losses.append(loss)\n","            total_plosses.append(ploss)\n","            total_vlosses.append(vloss)\n","            total_entropy.append(eloss)\n","            step += 1\n","\n","            # Report performance\n","            if step > 0 and step % 100 == 0:\n","                avg_reward = np.mean(total_rewards) / batch_size\n","                avg_loss = np.mean(total_losses)\n","                avg_ploss = np.mean(total_plosses)\n","                avg_vloss = np.mean(total_vlosses)\n","                avg_entropy = np.mean(total_entropy)\n","                total_losses, total_plosses, total_vlosses, total_entropy, total_rewards = [], [], [], [], []\n","                logger.info(\n","                        'epoch/step={:d}/{:d}'.format(epoch, step) +\n","                        ' | loss={:.5f}'.format(avg_loss) +\n","                        ' | ploss={:.5f}'.format(avg_ploss) +\n","                        ' | vloss={:.5f}'.format(avg_vloss) +\n","                        ' | entropy={:.5f}'.format(avg_entropy) +\n","                        ' | reward={:.5f}'.format(avg_reward))\n","        ### END of epoch ###\n","\n","        policy_file = '{}/policy_model_epoch_{}.ckpt'.format(log_dir, epoch)\n","        logger.info(\"Save model to \" + policy_file)\n","        torch.save(model.state_dict(), policy_file)\n","\n","\n","def main(dataset='challenge',name='train_agent',seed=123,gpu='0',epochs=1, batch_size=32,lr=1e-4,max_acts=250,max_path_len=3,\n","    gamma=0.99,ent_weight=1e-3,act_dropout=0.5,state_history=1,hidden=[512, 256]):\n","    os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n","    device = torch.device('cuda:0') if torch.cuda.is_available() else 'cpu'\n","\n","    log_dir = '{}/{}'.format(TMP_DIR['challenge'], name)\n","    if not os.path.isdir(log_dir):\n","        os.makedirs(log_dir)\n","\n","    global logger\n","    logger = get_logger(log_dir + '/train_log.txt')\n","    #logger.info(args)\n","\n","    set_random_seed(seed)\n","    train(dataset='challenge',name='train_agent',seed=123,gpu='0',epochs=1, batch_size=32,lr=1e-4,max_acts=250,max_path_len=3,\n","    gamma=0.99,ent_weight=1e-3,act_dropout=0.5,state_history=1,hidden=[512, 256],device=device,log_dir=log_dir)\n","\n","\n","if __name__ == '__main__':\n","    main(dataset='challenge',name='train_agent',seed=123,gpu='0',epochs=1, batch_size=32,lr=1e-4,max_acts=250,max_path_len=3,\n","    gamma=0.99,ent_weight=1e-3,act_dropout=0.5,state_history=1,hidden=[512, 256])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RKf1SgBinF43"},"outputs":[],"source":["import argparse\n","from math import log\n","from datetime import datetime\n","from tqdm import tqdm\n","from collections import namedtuple\n","import torch.optim as optim\n","from torch.autograd import Variable\n","from torch.distributions import Categorical\n","import threading\n","from functools import reduce"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XNh_clyTnF43","executionInfo":{"status":"ok","timestamp":1689936507090,"user_tz":-60,"elapsed":25313,"user":{"displayName":"huan chen","userId":"01704466685251061733"}},"outputId":"5a27d533-1072-4b1e-bed6-88385bb5225b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Predicting paths...\n","Load embedding: ./tmp/Challenge_Dataset/transe_embed.pkl\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/463 [00:00<?, ?it/s]<ipython-input-17-f55a25594160>:29: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at ../aten/src/ATen/native/cuda/Indexing.cu:1440.)\n","  actor_logits[1 - act_mask] = -999999.0\n","464it [00:23, 19.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Load embedding: ./tmp/Challenge_Dataset/transe_embed.pkl\n","MAP=42.675 | NDCG=59.918 |  Recall=24.525 | Precision=59.761\n"]}],"source":["def evaluate(topk_matches, test_user_articles):\n","    \"\"\"Compute metrics for predicted recommendations.\n","    Args:\n","        topk_matches: a list or dict of product ids in ascending order.\n","    \"\"\"\n","    invalid_users = []\n","    # Compute metrics\n","    precisions, recalls, ndcgs, hits, map_scores = [], [], [], [], []\n","    test_user_idxs = list(test_user_articles.keys())\n","    pred_real_articles,pred_l,real_l=[],[],[]\n","    for uid in test_user_idxs:\n","        if uid not in topk_matches or len(topk_matches[uid]) < 10:\n","            invalid_users.append(uid)\n","            continue\n","        pred_list, rel_set = topk_matches[uid][::-1], test_user_articles[uid]\n","        #print(\"uid:\",uid,\"pred_list:\",pred_list,\"real_set:\",rel_set)\n","        pred_real = \"uid:\"+str(uid)+' '+\"pred_list:\"+str(pred_list)+' '+\"rel_set:\"+str(rel_set)\n","        pred_real_articles.append(pred_real)\n","        pred_l.append(pred_list)\n","        real_l.append(rel_set)\n","        #print(pred_real_articles)\n","        if len(pred_list) == 0:\n","            continue\n","        #print(\"uid:\",uid, \"pred_list:\",pred_list, \"rel_set:\",rel_set)\n","\n","        dcg = 0.0\n","        hit_num = 0.0\n","        for i in range(len(pred_list)):\n","            if pred_list[i] in rel_set:\n","                dcg += 1. / (log(i + 2) / log(2))\n","                hit_num += 1\n","        # idcg\n","        idcg = 0.0\n","        for i in range(min(len(rel_set), len(pred_list))):\n","            idcg += 1. / (log(i + 2) / log(2))\n","        ndcg = dcg / idcg\n","        recall = hit_num / len(rel_set)\n","        precision = hit_num / len(pred_list)\n","        hit = 1.0 if hit_num > 0.0 else 0.0\n","\n","        #map\n","        map_score = 0.0\n","        num_hits = 0.0\n","        score = 0.0\n","        for i,p in enumerate(pred_list):\n","            if p in rel_set and p not in pred_list[:i]:\n","                num_hits+=1.0\n","                score+=num_hits/(i+1.0)\n","        map_score = score/min(len(rel_set),10)\n","\n","        ndcgs.append(ndcg)\n","        recalls.append(recall)\n","        precisions.append(precision)\n","        hits.append(hit)\n","        map_scores.append(map_score)\n","\n","    with open(TMP_DIR['challenge'] + '/' +'pred_real_article.dat','wb+') as file:\n","        pickle.dump(pred_real_articles,file)\n","\n","    with open(TMP_DIR['challenge'] + '/' +'pred_list.dat','wb+') as file:\n","        pickle.dump(pred_l,file)\n","\n","    with open(TMP_DIR['challenge'] + '/' +'real_list.dat','wb+') as file:\n","        pickle.dump(real_l,file)\n","\n","    avg_precision = np.mean(precisions) * 100\n","    avg_recall = np.mean(recalls) * 100\n","    avg_ndcg = np.mean(ndcgs) * 100\n","    avg_hit = np.mean(hits) * 100\n","    avg_map = np.mean(map_scores) * 100\n","\n","    tmp = 'map: '+str(avg_map)+' '+'ndcg: '+str(avg_ndcg)+ ' '+'recall: '+str(avg_recall)+' '+'precision: '+str(avg_precision)+' '+str(len(invalid_users))\n","    pickle.dump(tmp, open(log_dir + '/result.txt', 'wb'))\n","\n","    print('MAP={:.3f} | NDCG={:.3f} |  Recall={:.3f} | Precision={:.3f}'.format(\n","            avg_map, avg_ndcg, avg_recall, avg_precision))\n","\n","\n","def batch_beam_search(env, model, uids, device, topk=[25, 5, 1]):\n","    def _batch_acts_to_masks(batch_acts):\n","        batch_masks = []\n","        for acts in batch_acts:\n","            num_acts = len(acts)\n","            act_mask = np.zeros(model.act_dim, dtype=np.uint8)\n","            act_mask[:num_acts] = 1\n","            batch_masks.append(act_mask)\n","        return np.vstack(batch_masks)\n","\n","    state_pool = env.reset(uids)  # numpy of [bs, dim]\n","    path_pool = env._batch_path  # list of list, size=bs\n","    probs_pool = [[] for _ in uids]\n","    model.eval()\n","    for hop in range(3):\n","        state_tensor = torch.FloatTensor(state_pool).to(device)\n","        acts_pool = env._batch_get_actions(path_pool, False)  # list of list, size=bs\n","        actmask_pool = _batch_acts_to_masks(acts_pool)  # numpy of [bs, dim]\n","        actmask_tensor = torch.ByteTensor(actmask_pool).to(device)\n","        probs, _ = model((state_tensor, actmask_tensor))  # Tensor of [bs, act_dim]\n","        probs = probs + actmask_tensor.float()  # In order to differ from masked actions\n","        topk_probs, topk_idxs = torch.topk(probs, topk[hop], dim=1)  # LongTensor of [bs, k]\n","        topk_idxs = topk_idxs.detach().cpu().numpy()\n","        topk_probs = topk_probs.detach().cpu().numpy()\n","\n","        new_path_pool, new_probs_pool = [], []\n","        for row in range(topk_idxs.shape[0]):\n","            path = path_pool[row]\n","            probs = probs_pool[row]\n","            for idx, p in zip(topk_idxs[row], topk_probs[row]):\n","                if idx >= len(acts_pool[row]):  # act idx is invalid\n","                    continue\n","                relation, next_node_id = acts_pool[row][idx]  # (relation, next_node_id)\n","                if relation == SELF_LOOP:\n","                    next_node_type = path[-1][1]\n","                else:\n","                    next_node_type = KG_RELATION[path[-1][1]][relation]\n","                new_path = path + [(relation, next_node_type, next_node_id)]\n","                new_path_pool.append(new_path)\n","                new_probs_pool.append(probs + [p])\n","        path_pool = new_path_pool\n","        probs_pool = new_probs_pool\n","        if hop < 2:\n","            state_pool = env._batch_get_state(path_pool)\n","\n","    return path_pool, probs_pool\n","\n","\n","def predict_paths(policy_file, path_file, dataset='challenge',name='train_agent',log_dir='./', device='cuda', seed=123,gpu='0',epochs=1,max_acts=250,max_path_len=5,\n","         gamma=0.99,state_history=1,hidden=[512,256],add_articles=False,topk=[25, 5, 1],run_path=True,run_eval=True):\n","    print('Predicting paths...')\n","    env = BatchKGEnvironment(dataset, max_acts, max_path_len=max_path_len, state_history=state_history)\n","    pretrain_sd = torch.load(policy_file, map_location=torch.device('cpu'))\n","    #print(env.state_dim,env.act_dim)\n","    model = ActorCritic(env.state_dim, env.act_dim, gamma=gamma, hidden_sizes=hidden).to(device)\n","    model_sd = model.state_dict()\n","    model_sd.update(pretrain_sd)\n","    model.load_state_dict(model_sd)\n","\n","    test_labels = load_labels(dataset, 'test')\n","    test_uids = list(test_labels.keys())\n","\n","    batch_size = 16\n","    start_idx = 0\n","    all_paths, all_probs = [], []\n","    pbar = tqdm(total=len(test_uids))\n","    while start_idx < len(test_uids):\n","        end_idx = min(start_idx + batch_size, len(test_uids))\n","        batch_uids = test_uids[start_idx:end_idx]\n","        paths, probs = batch_beam_search(env, model, batch_uids, device, topk=topk)\n","        all_paths.extend(paths)\n","        all_probs.extend(probs)\n","        start_idx = end_idx\n","        pbar.update(batch_size)\n","    predicts = {'paths': all_paths, 'probs': all_probs}\n","    pickle.dump(predicts, open(path_file, 'wb'))\n","\n","\n","def evaluate_paths(path_file, train_labels, test_labels, add_articles=False):\n","    embeds = load_embed('challenge')\n","    user_embeds = embeds[USER]\n","    response_embeds = embeds[ARTICLE][0]\n","    article_embeds = embeds[ARTICLE]\n","    scores = np.dot(user_embeds + response_embeds, article_embeds.T)\n","\n","    # 1) Get all valid paths for each user, compute path score and path probability.\n","    results = pickle.load(open(path_file, 'rb'))\n","    #print(\"result_path:\",results['paths'])\n","    pred_paths = {uid: {} for uid in test_labels}\n","    for path, probs in zip(results['paths'], results['probs']):\n","        if path[-1][1] != ARTICLE:\n","            continue\n","        uid = path[0][2]\n","        if uid not in pred_paths:\n","            continue\n","        aid = path[-1][2]\n","        if aid not in pred_paths[uid]:\n","            pred_paths[uid][aid] = []\n","        path_score = scores[uid][aid]\n","        path_prob = reduce(lambda x, y: x * y, probs)\n","        pred_paths[uid][aid].append((path_score, path_prob, path))\n","\n","    # 2) Pick best path for each user-product pair, also remove pid if it is in train set.\n","    best_pred_paths = {}\n","    for uid in pred_paths:\n","        if uid in train_labels:\n","            train_aids = set(train_labels[uid])\n","            best_pred_paths[uid] = []\n","            for aid in pred_paths[uid]:\n","                if aid in train_aids:\n","                    continue\n","                # Get the path with highest probability\n","                #print(\"pred_path:\",pred_paths)\n","                sorted_path = sorted(pred_paths[uid][aid], key=lambda x: x[1], reverse=True)\n","                best_pred_paths[uid].append(sorted_path[0])\n","    #print(\"best_pred_path:\",best_pred_paths)\n","\n","    with open(TMP_DIR['challenge'] + '/' +'best_pred_path.dat','wb+') as file:\n","        pickle.dump(best_pred_paths,file)\n","\n","    # 3) Compute top 10 recommended articls for each user.\n","    top10_pred_paths = {}\n","    sort_by = 'score'\n","    pred_labels = {}\n","    for uid in best_pred_paths:\n","\n","        top10_pred_paths[uid] = []\n","\n","        if sort_by == 'score':\n","            sorted_path = sorted(best_pred_paths[uid], key=lambda x: (x[0], x[1]), reverse=True)\n","        elif sort_by == 'prob':\n","            sorted_path = sorted(best_pred_paths[uid], key=lambda x: (x[1], x[0]), reverse=True)\n","\n","        top10_pred_paths[uid].append(sorted_path[:10])\n","\n","        top10_aids = [p[-1][2] for _, _, p in sorted_path[:10]]  # from largest to smallest\n","        # add up to 10 pids if not enough\n","        if add_articles and len(top10_aids) < 10:\n","            train_aids = set(train_labels[uid])\n","            cand_aids = np.argsort(scores[uid])\n","            for cand_aid in cand_aids[::-1]:\n","                if cand_aid in train_aids or cand_aid in top10_aids:\n","                    continue\n","                top10_aids.append(cand_aid)\n","                if len(top10_aids) >= 10:\n","                    break\n","        # end of add\n","        pred_labels[uid] = top10_aids[::-1]  # change order to from smallest to largest!\n","\n","    with open(TMP_DIR['challenge'] + '/' +'top10_pred_paths.dat','wb+') as file:\n","        pickle.dump(top10_pred_paths,file)\n","\n","    evaluate(pred_labels, test_labels)\n","\n","\n","def test(dataset='challenge',name='train_agent',log_dir='./', device='cuda', seed=123,gpu='0',epochs=1,max_acts=250,max_path_len=5,\n","         gamma=0.99,state_history=1,hidden=[512,256],add_articles=False,topk=[25, 5, 1],run_path=True,run_eval=True):\n","\n","    policy_file = log_dir + '/policy_model_epoch_{}.ckpt'.format(epochs)\n","    path_file = log_dir + '/policy_paths_epoch{}.pkl'.format(epochs)\n","\n","    train_labels = load_labels(dataset, 'train')\n","    test_labels = load_labels(dataset, 'test')\n","\n","    if run_path:\n","        predict_paths(policy_file, path_file, dataset='challenge',name='train_agent',log_dir='./', device='cuda', seed=123,gpu='0',epochs=1,max_acts=250,max_path_len=5,\n","         gamma=0.99,state_history=1,hidden=[512,256],add_articles=False,topk=[25, 5, 1],run_path=True,run_eval=True)\n","    if run_eval:\n","        evaluate_paths(path_file, train_labels, test_labels)\n","\n","\n","if __name__ == '__main__':\n","    boolean = lambda x: (str(x).lower() == 'true')\n","    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n","    device = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n","\n","    log_dir = TMP_DIR['challenge'] + '/' + 'train_agent'\n","    test(dataset='challenge',name='train_agent',log_dir=log_dir, device=device, seed=123,gpu='0',epochs=1,max_acts=250,max_path_len=5,\n","         gamma=0.99,state_history=1,hidden=[512,256],add_articles=False,topk=[25, 5, 1],run_path=True,run_eval=True)"]}],"metadata":{"instance_type":"ml.g4dn.12xlarge","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"lcc_arn":"arn:aws:sagemaker:us-east-1:647324198242:studio-lifecycle-config/dlsg-sagemaker-kernel-on-start-e8130f","colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}