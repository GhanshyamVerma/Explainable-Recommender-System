{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aWXPH78vnF4x","executionInfo":{"status":"ok","timestamp":1689083302470,"user_tz":-60,"elapsed":2654,"user":{"displayName":"huan chen","userId":"01704466685251061733"}},"outputId":"b4ae25f4-9873-4f27-de18-6d3053e0ba1c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://download.pytorch.org/whl/cpu/torch_stable.html\n","\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.0.1 (from versions: 1.11.0, 1.11.0+cpu, 1.12.0, 1.12.0+cpu, 1.12.1, 1.12.1+cpu, 1.13.0, 1.13.0+cpu, 1.13.1, 1.13.1+cpu, 2.0.0, 2.0.0+cpu, 2.0.1, 2.0.1+cpu)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.0.1\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip3 install torch==1.0.1 torchvision==0.2.2 -f https://download.pytorch.org/whl/cpu/torch_stable.html"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0-g61FN7nF4z","executionInfo":{"status":"ok","timestamp":1689085808011,"user_tz":-60,"elapsed":3792,"user":{"displayName":"huan chen","userId":"01704466685251061733"}},"outputId":"ff95a573-5c29-43b9-c7db-79b57ec66225"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: easydict in /usr/local/lib/python3.10/dist-packages (1.10)\n"]}],"source":["!pip3 install easydict"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"dKHTX4UMnF4z","executionInfo":{"status":"ok","timestamp":1689085818277,"user_tz":-60,"elapsed":846,"user":{"displayName":"huan chen","userId":"01704466685251061733"}}},"outputs":[],"source":["# Proprocess the data, create kg etc.\n","from __future__ import absolute_import, division, print_function\n","\n","import os\n","import pickle\n","import gzip\n","\n","import data_utils\n","import utils\n","\n","from utils import *\n","from data_utils import ChallengeDataset, ChallengeDataLoader\n","from knowledge_graph import KnowledgeGraph"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ukmt20xbnF4z","executionInfo":{"status":"ok","timestamp":1689084427409,"user_tz":-60,"elapsed":41608,"user":{"displayName":"huan chen","userId":"01704466685251061733"}},"outputId":"a7ad6a3c-ccb2-46d0-cd69-04830829ae87"},"outputs":[{"output_type":"stream","name":"stdout","text":["Load challenge dataset from file...\n","Load user of size 463\n","Load article of size 71\n","Load word of size 2246\n","Load related_article of size 71\n","Load topic of size 55\n","Load product of size 64\n","Load topic_tag of size 24\n","Load product_tag of size 45\n","Load has_topic of size 71\n","Load has_product of size 71\n","Load also_response of size 71\n","Load recommended_together of size 71\n","Load response_together of size 71\n","Load has_topic_tag of size 71\n","Load has_product_tag of size 71\n","Load text of size 26172 word count= 10415868\n","Create word sampling rate\n","Create challenge knowledge graph from dataset...\n","Load entities...\n","Total 3039 nodes.\n","Load text...\n","Total 269374 text edges.\n","Load knowledge has_topic...\n","Total 566 has_topic edges.\n","Load knowledge has_product...\n","Total 720 has_product edges.\n","Load knowledge also_response...\n","Total 7318 also_response edges.\n","Load knowledge recommended_together...\n","Total 534 recommended_together edges.\n","Load knowledge response_together...\n","Total 142 response_together edges.\n","Load knowledge has_topic_tag...\n","Total 132 has_topic_tag edges.\n","Load knowledge has_product_tag...\n","Total 284 has_product_tag edges.\n","Remove duplicates...\n","Compute node degrees...\n","Generate challenge train/test labels.\n"]}],"source":["def generate_labels(dataset, mode='train'):\n","    review_file = '{}/{}.txt'.format(DATASET_DIR[dataset], mode)\n","    user_articles = {}  # {uid: [aid,...], ...}\n","    with open(review_file, 'r') as f:\n","        for line in f:\n","            line = line.strip()\n","            arr = line.split('\\t')\n","            user_idx = int(arr[0])\n","            article_idx = int(arr[1])\n","            if user_idx not in user_articles:\n","                user_articles[user_idx] = []\n","            user_articles[user_idx].append(article_idx)\n","    save_labels(dataset, user_articles, mode=mode)\n","\n","\n","def main(data):\n","    dataset_n = data\n","\n","    # Create Dataset instance for dataset.\n","    # ========== BEGIN ========== #\n","    print('Load', dataset_n, 'dataset from file...')\n","    if not os.path.isdir(TMP_DIR[dataset_n]):\n","        os.makedirs(TMP_DIR[dataset_n])\n","    dataset = ChallengeDataset(DATASET_DIR[dataset_n])\n","    save_dataset(dataset_n, dataset)\n","\n","    # Generate knowledge graph instance.\n","    # ========== BEGIN ========== #\n","\n","    print('Create', dataset_n, 'knowledge graph from dataset...')\n","    dataset = load_dataset(dataset_n)\n","    kg = KnowledgeGraph(dataset)\n","    kg.compute_degrees()\n","    save_kg(dataset_n, kg)\n","    # =========== END =========== #\n","\n","    # Genereate train/test labels.\n","    # ========== BEGIN ========== #\n","    print('Generate', dataset_n, 'train/test labels.')\n","    generate_labels(dataset_n, 'train')\n","    generate_labels(dataset_n, 'test')\n","    # =========== END =========== #\n","\n","\n","if __name__ == '__main__':\n","    main(\"challenge\")"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"0TCEwPMMnF40","executionInfo":{"status":"ok","timestamp":1689085824526,"user_tz":-60,"elapsed":426,"user":{"displayName":"huan chen","userId":"01704466685251061733"}}},"outputs":[],"source":["import sys\n","import random\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","from transe_model import KnowledgeEmbedding"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ic8cR_2MnF40","executionInfo":{"status":"ok","timestamp":1689085598191,"user_tz":-60,"elapsed":1116840,"user":{"displayName":"huan chen","userId":"01704466685251061733"}},"outputId":"0b2a5a2e-bcb2-4c7a-d503-9d36b6e88c67"},"outputs":[{"output_type":"stream","name":"stdout","text":["./tmp/Challenge_Dataset/train_transe_model\n","[INFO]  Epoch: 01 | Words: 30827/10415869 | Lr: 0.00500 | Smooth loss: 39.43568\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 30827/10415869 | Lr: 0.00500 | Smooth loss: 39.43568\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 61780/10415869 | Lr: 0.00500 | Smooth loss: 37.66363\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 61780/10415869 | Lr: 0.00500 | Smooth loss: 37.66363\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 92723/10415869 | Lr: 0.00500 | Smooth loss: 36.95670\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 92723/10415869 | Lr: 0.00500 | Smooth loss: 36.95670\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 123830/10415869 | Lr: 0.00500 | Smooth loss: 36.42055\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 123830/10415869 | Lr: 0.00500 | Smooth loss: 36.42055\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 154269/10415869 | Lr: 0.00500 | Smooth loss: 35.44751\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 154269/10415869 | Lr: 0.00500 | Smooth loss: 35.44751\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 183348/10415869 | Lr: 0.00500 | Smooth loss: 34.82703\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 183348/10415869 | Lr: 0.00500 | Smooth loss: 34.82703\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 213167/10415869 | Lr: 0.00500 | Smooth loss: 34.63976\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 213167/10415869 | Lr: 0.00500 | Smooth loss: 34.63976\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 244052/10415869 | Lr: 0.00500 | Smooth loss: 34.50105\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 244052/10415869 | Lr: 0.00500 | Smooth loss: 34.50105\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 274489/10415869 | Lr: 0.00500 | Smooth loss: 34.36412\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 274489/10415869 | Lr: 0.00500 | Smooth loss: 34.36412\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 305945/10415869 | Lr: 0.00500 | Smooth loss: 33.49326\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 305945/10415869 | Lr: 0.00500 | Smooth loss: 33.49326\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 335998/10415869 | Lr: 0.00500 | Smooth loss: 33.13676\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 335998/10415869 | Lr: 0.00500 | Smooth loss: 33.13676\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 365960/10415869 | Lr: 0.00500 | Smooth loss: 32.94880\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 365960/10415869 | Lr: 0.00500 | Smooth loss: 32.94880\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 396122/10415869 | Lr: 0.00500 | Smooth loss: 32.33093\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 396122/10415869 | Lr: 0.00500 | Smooth loss: 32.33093\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 426143/10415869 | Lr: 0.00500 | Smooth loss: 32.29373\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 426143/10415869 | Lr: 0.00500 | Smooth loss: 32.29373\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 456853/10415869 | Lr: 0.00500 | Smooth loss: 31.99604\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 456853/10415869 | Lr: 0.00500 | Smooth loss: 31.99604\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 487742/10415869 | Lr: 0.00500 | Smooth loss: 31.53190\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 487742/10415869 | Lr: 0.00500 | Smooth loss: 31.53190\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 516764/10415869 | Lr: 0.00500 | Smooth loss: 30.77948\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 516764/10415869 | Lr: 0.00500 | Smooth loss: 30.77948\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 547682/10415869 | Lr: 0.00500 | Smooth loss: 30.56103\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 547682/10415869 | Lr: 0.00500 | Smooth loss: 30.56103\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 577187/10415869 | Lr: 0.00500 | Smooth loss: 29.79408\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 577187/10415869 | Lr: 0.00500 | Smooth loss: 29.79408\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 608021/10415869 | Lr: 0.00500 | Smooth loss: 29.13499\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 608021/10415869 | Lr: 0.00500 | Smooth loss: 29.13499\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 637748/10415869 | Lr: 0.00500 | Smooth loss: 28.73557\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 637748/10415869 | Lr: 0.00500 | Smooth loss: 28.73557\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 667396/10415869 | Lr: 0.00500 | Smooth loss: 28.58241\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 667396/10415869 | Lr: 0.00500 | Smooth loss: 28.58241\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 698274/10415869 | Lr: 0.00500 | Smooth loss: 28.17532\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 698274/10415869 | Lr: 0.00500 | Smooth loss: 28.17532\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 728225/10415869 | Lr: 0.00500 | Smooth loss: 27.56062\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 728225/10415869 | Lr: 0.00500 | Smooth loss: 27.56062\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 758326/10415869 | Lr: 0.00500 | Smooth loss: 28.14258\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 758326/10415869 | Lr: 0.00500 | Smooth loss: 28.14258\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 788171/10415869 | Lr: 0.00500 | Smooth loss: 27.75833\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 788171/10415869 | Lr: 0.00500 | Smooth loss: 27.75833\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 818937/10415869 | Lr: 0.00500 | Smooth loss: 27.60831\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 818937/10415869 | Lr: 0.00500 | Smooth loss: 27.60831\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 850176/10415869 | Lr: 0.00500 | Smooth loss: 27.51412\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 850176/10415869 | Lr: 0.00500 | Smooth loss: 27.51412\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 881082/10415869 | Lr: 0.00500 | Smooth loss: 27.59858\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 881082/10415869 | Lr: 0.00500 | Smooth loss: 27.59858\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 911326/10415869 | Lr: 0.00500 | Smooth loss: 27.11798\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 911326/10415869 | Lr: 0.00500 | Smooth loss: 27.11798\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 942421/10415869 | Lr: 0.00500 | Smooth loss: 27.29641\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 942421/10415869 | Lr: 0.00500 | Smooth loss: 27.29641\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 972116/10415869 | Lr: 0.00500 | Smooth loss: 27.48286\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 972116/10415869 | Lr: 0.00500 | Smooth loss: 27.48286\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1003983/10415869 | Lr: 0.00500 | Smooth loss: 27.28507\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1003983/10415869 | Lr: 0.00500 | Smooth loss: 27.28507\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1034286/10415869 | Lr: 0.00500 | Smooth loss: 26.63320\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1034286/10415869 | Lr: 0.00500 | Smooth loss: 26.63320\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1064632/10415869 | Lr: 0.00500 | Smooth loss: 26.57558\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1064632/10415869 | Lr: 0.00500 | Smooth loss: 26.57558\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1095356/10415869 | Lr: 0.00500 | Smooth loss: 27.18974\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1095356/10415869 | Lr: 0.00500 | Smooth loss: 27.18974\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1124268/10415869 | Lr: 0.00500 | Smooth loss: 26.69901\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1124268/10415869 | Lr: 0.00500 | Smooth loss: 26.69901\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1154079/10415869 | Lr: 0.00500 | Smooth loss: 26.99009\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1154079/10415869 | Lr: 0.00500 | Smooth loss: 26.99009\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1184238/10415869 | Lr: 0.00500 | Smooth loss: 26.68549\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1184238/10415869 | Lr: 0.00500 | Smooth loss: 26.68549\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1213820/10415869 | Lr: 0.00500 | Smooth loss: 26.92927\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1213820/10415869 | Lr: 0.00500 | Smooth loss: 26.92927\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1244898/10415869 | Lr: 0.00500 | Smooth loss: 26.87181\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1244898/10415869 | Lr: 0.00500 | Smooth loss: 26.87181\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1275065/10415869 | Lr: 0.00500 | Smooth loss: 27.09492\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1275065/10415869 | Lr: 0.00500 | Smooth loss: 27.09492\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1305133/10415869 | Lr: 0.00500 | Smooth loss: 26.50398\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1305133/10415869 | Lr: 0.00500 | Smooth loss: 26.50398\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1335698/10415869 | Lr: 0.00500 | Smooth loss: 26.10354\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1335698/10415869 | Lr: 0.00500 | Smooth loss: 26.10354\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1366357/10415869 | Lr: 0.00500 | Smooth loss: 26.44155\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1366357/10415869 | Lr: 0.00500 | Smooth loss: 26.44155\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1396701/10415869 | Lr: 0.00500 | Smooth loss: 26.52685\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1396701/10415869 | Lr: 0.00500 | Smooth loss: 26.52685\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1426917/10415869 | Lr: 0.00500 | Smooth loss: 26.38655\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1426917/10415869 | Lr: 0.00500 | Smooth loss: 26.38655\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1456523/10415869 | Lr: 0.00500 | Smooth loss: 26.18031\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1456523/10415869 | Lr: 0.00500 | Smooth loss: 26.18031\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1486068/10415869 | Lr: 0.00500 | Smooth loss: 26.07646\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1486068/10415869 | Lr: 0.00500 | Smooth loss: 26.07646\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1515301/10415869 | Lr: 0.00500 | Smooth loss: 25.18661\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1515301/10415869 | Lr: 0.00500 | Smooth loss: 25.18661\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1544860/10415869 | Lr: 0.00500 | Smooth loss: 25.62972\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1544860/10415869 | Lr: 0.00500 | Smooth loss: 25.62972\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1574829/10415869 | Lr: 0.00500 | Smooth loss: 26.37865\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1574829/10415869 | Lr: 0.00500 | Smooth loss: 26.37865\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1605235/10415869 | Lr: 0.00500 | Smooth loss: 26.33342\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1605235/10415869 | Lr: 0.00500 | Smooth loss: 26.33342\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1636530/10415869 | Lr: 0.00500 | Smooth loss: 25.07833\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1636530/10415869 | Lr: 0.00500 | Smooth loss: 25.07833\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1666932/10415869 | Lr: 0.00500 | Smooth loss: 26.67209\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1666932/10415869 | Lr: 0.00500 | Smooth loss: 26.67209\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1697150/10415869 | Lr: 0.00500 | Smooth loss: 24.94726\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1697150/10415869 | Lr: 0.00500 | Smooth loss: 24.94726\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1727422/10415869 | Lr: 0.00500 | Smooth loss: 25.77111\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1727422/10415869 | Lr: 0.00500 | Smooth loss: 25.77111\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1757671/10415869 | Lr: 0.00500 | Smooth loss: 25.55029\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1757671/10415869 | Lr: 0.00500 | Smooth loss: 25.55029\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1787416/10415869 | Lr: 0.00500 | Smooth loss: 25.24614\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1787416/10415869 | Lr: 0.00500 | Smooth loss: 25.24614\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1817582/10415869 | Lr: 0.00500 | Smooth loss: 25.71897\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1817582/10415869 | Lr: 0.00500 | Smooth loss: 25.71897\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1847523/10415869 | Lr: 0.00500 | Smooth loss: 25.03195\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1847523/10415869 | Lr: 0.00500 | Smooth loss: 25.03195\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1879041/10415869 | Lr: 0.00500 | Smooth loss: 24.71859\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1879041/10415869 | Lr: 0.00500 | Smooth loss: 24.71859\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1910219/10415869 | Lr: 0.00500 | Smooth loss: 24.97933\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1910219/10415869 | Lr: 0.00500 | Smooth loss: 24.97933\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1941032/10415869 | Lr: 0.00500 | Smooth loss: 24.47631\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1941032/10415869 | Lr: 0.00500 | Smooth loss: 24.47631\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 1970703/10415869 | Lr: 0.00500 | Smooth loss: 24.60825\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 1970703/10415869 | Lr: 0.00500 | Smooth loss: 24.60825\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2001198/10415869 | Lr: 0.00500 | Smooth loss: 24.86247\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2001198/10415869 | Lr: 0.00500 | Smooth loss: 24.86247\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2031817/10415869 | Lr: 0.00500 | Smooth loss: 24.84907\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2031817/10415869 | Lr: 0.00500 | Smooth loss: 24.84907\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2061839/10415869 | Lr: 0.00500 | Smooth loss: 25.69571\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2061839/10415869 | Lr: 0.00500 | Smooth loss: 25.69571\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2091841/10415869 | Lr: 0.00500 | Smooth loss: 24.76884\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2091841/10415869 | Lr: 0.00500 | Smooth loss: 24.76884\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2122848/10415869 | Lr: 0.00500 | Smooth loss: 25.19510\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2122848/10415869 | Lr: 0.00500 | Smooth loss: 25.19510\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2153340/10415869 | Lr: 0.00500 | Smooth loss: 24.17419\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2153340/10415869 | Lr: 0.00500 | Smooth loss: 24.17419\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2184861/10415869 | Lr: 0.00500 | Smooth loss: 24.76258\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2184861/10415869 | Lr: 0.00500 | Smooth loss: 24.76258\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2214598/10415869 | Lr: 0.00500 | Smooth loss: 24.34293\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2214598/10415869 | Lr: 0.00500 | Smooth loss: 24.34293\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2244390/10415869 | Lr: 0.00500 | Smooth loss: 24.69181\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2244390/10415869 | Lr: 0.00500 | Smooth loss: 24.69181\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2275296/10415869 | Lr: 0.00500 | Smooth loss: 24.57088\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2275296/10415869 | Lr: 0.00500 | Smooth loss: 24.57088\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2305883/10415869 | Lr: 0.00500 | Smooth loss: 24.67213\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2305883/10415869 | Lr: 0.00500 | Smooth loss: 24.67213\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2336227/10415869 | Lr: 0.00500 | Smooth loss: 24.52508\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2336227/10415869 | Lr: 0.00500 | Smooth loss: 24.52508\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2366365/10415869 | Lr: 0.00500 | Smooth loss: 23.12649\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2366365/10415869 | Lr: 0.00500 | Smooth loss: 23.12649\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2397945/10415869 | Lr: 0.00500 | Smooth loss: 23.77083\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2397945/10415869 | Lr: 0.00500 | Smooth loss: 23.77083\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2427050/10415869 | Lr: 0.00500 | Smooth loss: 24.11041\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2427050/10415869 | Lr: 0.00500 | Smooth loss: 24.11041\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2458029/10415869 | Lr: 0.00500 | Smooth loss: 24.12463\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2458029/10415869 | Lr: 0.00500 | Smooth loss: 24.12463\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2487667/10415869 | Lr: 0.00500 | Smooth loss: 23.80329\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2487667/10415869 | Lr: 0.00500 | Smooth loss: 23.80329\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2517632/10415869 | Lr: 0.00500 | Smooth loss: 24.17207\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2517632/10415869 | Lr: 0.00500 | Smooth loss: 24.17207\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2547684/10415869 | Lr: 0.00500 | Smooth loss: 23.35331\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2547684/10415869 | Lr: 0.00500 | Smooth loss: 23.35331\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2577003/10415869 | Lr: 0.00500 | Smooth loss: 23.88597\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2577003/10415869 | Lr: 0.00500 | Smooth loss: 23.88597\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2607540/10415869 | Lr: 0.00500 | Smooth loss: 22.91579\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2607540/10415869 | Lr: 0.00500 | Smooth loss: 22.91579\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2636969/10415869 | Lr: 0.00500 | Smooth loss: 24.38336\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2636969/10415869 | Lr: 0.00500 | Smooth loss: 24.38336\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2668087/10415869 | Lr: 0.00500 | Smooth loss: 24.47375\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2668087/10415869 | Lr: 0.00500 | Smooth loss: 24.47375\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2698226/10415869 | Lr: 0.00500 | Smooth loss: 23.86887\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2698226/10415869 | Lr: 0.00500 | Smooth loss: 23.86887\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2729078/10415869 | Lr: 0.00500 | Smooth loss: 23.78691\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2729078/10415869 | Lr: 0.00500 | Smooth loss: 23.78691\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2760069/10415869 | Lr: 0.00500 | Smooth loss: 24.71466\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2760069/10415869 | Lr: 0.00500 | Smooth loss: 24.71466\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2789180/10415869 | Lr: 0.00500 | Smooth loss: 23.00277\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2789180/10415869 | Lr: 0.00500 | Smooth loss: 23.00277\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2818987/10415869 | Lr: 0.00500 | Smooth loss: 23.91140\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2818987/10415869 | Lr: 0.00500 | Smooth loss: 23.91140\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2849703/10415869 | Lr: 0.00500 | Smooth loss: 23.69460\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2849703/10415869 | Lr: 0.00500 | Smooth loss: 23.69460\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2879195/10415869 | Lr: 0.00500 | Smooth loss: 22.97622\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2879195/10415869 | Lr: 0.00500 | Smooth loss: 22.97622\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2908602/10415869 | Lr: 0.00500 | Smooth loss: 24.02043\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2908602/10415869 | Lr: 0.00500 | Smooth loss: 24.02043\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2939752/10415869 | Lr: 0.00500 | Smooth loss: 23.90981\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2939752/10415869 | Lr: 0.00500 | Smooth loss: 23.90981\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2969163/10415869 | Lr: 0.00500 | Smooth loss: 23.05473\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2969163/10415869 | Lr: 0.00500 | Smooth loss: 23.05473\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 2998383/10415869 | Lr: 0.00500 | Smooth loss: 22.81134\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 2998383/10415869 | Lr: 0.00500 | Smooth loss: 22.81134\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3028086/10415869 | Lr: 0.00500 | Smooth loss: 23.16538\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3028086/10415869 | Lr: 0.00500 | Smooth loss: 23.16538\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3057555/10415869 | Lr: 0.00500 | Smooth loss: 23.13977\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3057555/10415869 | Lr: 0.00500 | Smooth loss: 23.13977\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3086651/10415869 | Lr: 0.00500 | Smooth loss: 24.28817\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3086651/10415869 | Lr: 0.00500 | Smooth loss: 24.28817\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3116963/10415869 | Lr: 0.00500 | Smooth loss: 23.55523\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3116963/10415869 | Lr: 0.00500 | Smooth loss: 23.55523\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3147827/10415869 | Lr: 0.00500 | Smooth loss: 23.01430\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3147827/10415869 | Lr: 0.00500 | Smooth loss: 23.01430\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3177123/10415869 | Lr: 0.00500 | Smooth loss: 22.23403\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3177123/10415869 | Lr: 0.00500 | Smooth loss: 22.23403\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3206844/10415869 | Lr: 0.00500 | Smooth loss: 23.65369\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3206844/10415869 | Lr: 0.00500 | Smooth loss: 23.65369\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3236376/10415869 | Lr: 0.00500 | Smooth loss: 23.54971\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3236376/10415869 | Lr: 0.00500 | Smooth loss: 23.54971\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3266142/10415869 | Lr: 0.00500 | Smooth loss: 22.73921\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3266142/10415869 | Lr: 0.00500 | Smooth loss: 22.73921\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3295829/10415869 | Lr: 0.00500 | Smooth loss: 23.52500\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3295829/10415869 | Lr: 0.00500 | Smooth loss: 23.52500\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3326421/10415869 | Lr: 0.00500 | Smooth loss: 22.61503\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3326421/10415869 | Lr: 0.00500 | Smooth loss: 22.61503\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3357408/10415869 | Lr: 0.00500 | Smooth loss: 22.90466\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3357408/10415869 | Lr: 0.00500 | Smooth loss: 22.90466\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3388126/10415869 | Lr: 0.00500 | Smooth loss: 23.32864\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3388126/10415869 | Lr: 0.00500 | Smooth loss: 23.32864\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3417997/10415869 | Lr: 0.00500 | Smooth loss: 23.39159\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3417997/10415869 | Lr: 0.00500 | Smooth loss: 23.39159\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3448542/10415869 | Lr: 0.00500 | Smooth loss: 23.45959\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3448542/10415869 | Lr: 0.00500 | Smooth loss: 23.45959\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3478427/10415869 | Lr: 0.00500 | Smooth loss: 22.74774\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3478427/10415869 | Lr: 0.00500 | Smooth loss: 22.74774\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3508806/10415869 | Lr: 0.00500 | Smooth loss: 22.55335\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3508806/10415869 | Lr: 0.00500 | Smooth loss: 22.55335\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3539806/10415869 | Lr: 0.00500 | Smooth loss: 22.81840\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3539806/10415869 | Lr: 0.00500 | Smooth loss: 22.81840\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3570289/10415869 | Lr: 0.00500 | Smooth loss: 22.03841\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3570289/10415869 | Lr: 0.00500 | Smooth loss: 22.03841\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3600378/10415869 | Lr: 0.00500 | Smooth loss: 22.06464\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3600378/10415869 | Lr: 0.00500 | Smooth loss: 22.06464\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3630561/10415869 | Lr: 0.00500 | Smooth loss: 23.09266\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3630561/10415869 | Lr: 0.00500 | Smooth loss: 23.09266\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3661159/10415869 | Lr: 0.00500 | Smooth loss: 23.21332\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3661159/10415869 | Lr: 0.00500 | Smooth loss: 23.21332\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3692093/10415869 | Lr: 0.00500 | Smooth loss: 22.99190\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3692093/10415869 | Lr: 0.00500 | Smooth loss: 22.99190\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3723698/10415869 | Lr: 0.00500 | Smooth loss: 22.26227\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3723698/10415869 | Lr: 0.00500 | Smooth loss: 22.26227\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3754339/10415869 | Lr: 0.00500 | Smooth loss: 22.65981\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3754339/10415869 | Lr: 0.00500 | Smooth loss: 22.65981\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3783615/10415869 | Lr: 0.00500 | Smooth loss: 21.81886\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3783615/10415869 | Lr: 0.00500 | Smooth loss: 21.81886\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3813933/10415869 | Lr: 0.00500 | Smooth loss: 23.07501\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3813933/10415869 | Lr: 0.00500 | Smooth loss: 23.07501\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3842944/10415869 | Lr: 0.00500 | Smooth loss: 22.51555\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3842944/10415869 | Lr: 0.00500 | Smooth loss: 22.51555\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3871611/10415869 | Lr: 0.00500 | Smooth loss: 22.63900\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3871611/10415869 | Lr: 0.00500 | Smooth loss: 22.63900\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3902314/10415869 | Lr: 0.00500 | Smooth loss: 23.26676\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3902314/10415869 | Lr: 0.00500 | Smooth loss: 23.26676\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3930770/10415869 | Lr: 0.00500 | Smooth loss: 22.84189\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3930770/10415869 | Lr: 0.00500 | Smooth loss: 22.84189\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3962041/10415869 | Lr: 0.00500 | Smooth loss: 22.40001\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3962041/10415869 | Lr: 0.00500 | Smooth loss: 22.40001\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 3993516/10415869 | Lr: 0.00500 | Smooth loss: 22.96900\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 3993516/10415869 | Lr: 0.00500 | Smooth loss: 22.96900\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4022746/10415869 | Lr: 0.00500 | Smooth loss: 23.06339\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4022746/10415869 | Lr: 0.00500 | Smooth loss: 23.06339\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4051918/10415869 | Lr: 0.00500 | Smooth loss: 22.18308\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4051918/10415869 | Lr: 0.00500 | Smooth loss: 22.18308\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4082308/10415869 | Lr: 0.00500 | Smooth loss: 22.12771\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4082308/10415869 | Lr: 0.00500 | Smooth loss: 22.12771\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4112549/10415869 | Lr: 0.00500 | Smooth loss: 23.15246\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4112549/10415869 | Lr: 0.00500 | Smooth loss: 23.15246\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4144052/10415869 | Lr: 0.00500 | Smooth loss: 23.33041\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4144052/10415869 | Lr: 0.00500 | Smooth loss: 23.33041\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4174114/10415869 | Lr: 0.00500 | Smooth loss: 22.84644\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4174114/10415869 | Lr: 0.00500 | Smooth loss: 22.84644\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4204842/10415869 | Lr: 0.00500 | Smooth loss: 22.56123\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4204842/10415869 | Lr: 0.00500 | Smooth loss: 22.56123\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4235003/10415869 | Lr: 0.00500 | Smooth loss: 22.44842\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4235003/10415869 | Lr: 0.00500 | Smooth loss: 22.44842\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4265889/10415869 | Lr: 0.00500 | Smooth loss: 22.80068\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4265889/10415869 | Lr: 0.00500 | Smooth loss: 22.80068\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4296017/10415869 | Lr: 0.00500 | Smooth loss: 22.87795\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4296017/10415869 | Lr: 0.00500 | Smooth loss: 22.87795\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4326325/10415869 | Lr: 0.00500 | Smooth loss: 22.23848\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4326325/10415869 | Lr: 0.00500 | Smooth loss: 22.23848\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4356223/10415869 | Lr: 0.00500 | Smooth loss: 22.50147\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4356223/10415869 | Lr: 0.00500 | Smooth loss: 22.50147\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4386318/10415869 | Lr: 0.00500 | Smooth loss: 22.13097\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4386318/10415869 | Lr: 0.00500 | Smooth loss: 22.13097\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4417690/10415869 | Lr: 0.00500 | Smooth loss: 21.88210\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4417690/10415869 | Lr: 0.00500 | Smooth loss: 21.88210\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4448268/10415869 | Lr: 0.00500 | Smooth loss: 21.98389\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4448268/10415869 | Lr: 0.00500 | Smooth loss: 21.98389\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4478785/10415869 | Lr: 0.00500 | Smooth loss: 21.83655\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4478785/10415869 | Lr: 0.00500 | Smooth loss: 21.83655\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4508241/10415869 | Lr: 0.00500 | Smooth loss: 21.83375\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4508241/10415869 | Lr: 0.00500 | Smooth loss: 21.83375\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4538030/10415869 | Lr: 0.00500 | Smooth loss: 22.25554\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4538030/10415869 | Lr: 0.00500 | Smooth loss: 22.25554\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4568305/10415869 | Lr: 0.00500 | Smooth loss: 22.41392\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4568305/10415869 | Lr: 0.00500 | Smooth loss: 22.41392\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4598425/10415869 | Lr: 0.00500 | Smooth loss: 22.77401\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4598425/10415869 | Lr: 0.00500 | Smooth loss: 22.77401\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4628955/10415869 | Lr: 0.00500 | Smooth loss: 22.52876\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4628955/10415869 | Lr: 0.00500 | Smooth loss: 22.52876\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4659364/10415869 | Lr: 0.00500 | Smooth loss: 22.16975\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4659364/10415869 | Lr: 0.00500 | Smooth loss: 22.16975\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4689089/10415869 | Lr: 0.00500 | Smooth loss: 21.44302\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4689089/10415869 | Lr: 0.00500 | Smooth loss: 21.44302\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4720226/10415869 | Lr: 0.00500 | Smooth loss: 22.49607\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4720226/10415869 | Lr: 0.00500 | Smooth loss: 22.49607\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4750522/10415869 | Lr: 0.00500 | Smooth loss: 22.62556\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4750522/10415869 | Lr: 0.00500 | Smooth loss: 22.62556\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4781076/10415869 | Lr: 0.00500 | Smooth loss: 22.78078\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4781076/10415869 | Lr: 0.00500 | Smooth loss: 22.78078\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4812330/10415869 | Lr: 0.00500 | Smooth loss: 22.50585\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4812330/10415869 | Lr: 0.00500 | Smooth loss: 22.50585\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4841687/10415869 | Lr: 0.00500 | Smooth loss: 22.30891\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4841687/10415869 | Lr: 0.00500 | Smooth loss: 22.30891\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4872952/10415869 | Lr: 0.00500 | Smooth loss: 22.38287\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4872952/10415869 | Lr: 0.00500 | Smooth loss: 22.38287\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4903426/10415869 | Lr: 0.00500 | Smooth loss: 21.49943\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4903426/10415869 | Lr: 0.00500 | Smooth loss: 21.49943\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4934240/10415869 | Lr: 0.00500 | Smooth loss: 22.52277\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4934240/10415869 | Lr: 0.00500 | Smooth loss: 22.52277\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4963782/10415869 | Lr: 0.00500 | Smooth loss: 22.05150\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4963782/10415869 | Lr: 0.00500 | Smooth loss: 22.05150\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 4993205/10415869 | Lr: 0.00500 | Smooth loss: 21.83172\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 4993205/10415869 | Lr: 0.00500 | Smooth loss: 21.83172\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5024080/10415869 | Lr: 0.00500 | Smooth loss: 22.46982\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5024080/10415869 | Lr: 0.00500 | Smooth loss: 22.46982\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5052765/10415869 | Lr: 0.00500 | Smooth loss: 21.64146\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5052765/10415869 | Lr: 0.00500 | Smooth loss: 21.64146\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5083303/10415869 | Lr: 0.00500 | Smooth loss: 22.07441\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5083303/10415869 | Lr: 0.00500 | Smooth loss: 22.07441\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5113152/10415869 | Lr: 0.00500 | Smooth loss: 22.10792\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5113152/10415869 | Lr: 0.00500 | Smooth loss: 22.10792\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5142265/10415869 | Lr: 0.00500 | Smooth loss: 21.96506\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5142265/10415869 | Lr: 0.00500 | Smooth loss: 21.96506\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5172254/10415869 | Lr: 0.00500 | Smooth loss: 21.62073\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5172254/10415869 | Lr: 0.00500 | Smooth loss: 21.62073\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5201780/10415869 | Lr: 0.00500 | Smooth loss: 22.07862\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5201780/10415869 | Lr: 0.00500 | Smooth loss: 22.07862\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5233338/10415869 | Lr: 0.00500 | Smooth loss: 22.37900\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5233338/10415869 | Lr: 0.00500 | Smooth loss: 22.37900\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5263790/10415869 | Lr: 0.00500 | Smooth loss: 21.09626\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5263790/10415869 | Lr: 0.00500 | Smooth loss: 21.09626\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5295072/10415869 | Lr: 0.00500 | Smooth loss: 21.79317\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5295072/10415869 | Lr: 0.00500 | Smooth loss: 21.79317\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5325203/10415869 | Lr: 0.00500 | Smooth loss: 21.47456\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5325203/10415869 | Lr: 0.00500 | Smooth loss: 21.47456\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5355653/10415869 | Lr: 0.00500 | Smooth loss: 21.43110\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5355653/10415869 | Lr: 0.00500 | Smooth loss: 21.43110\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5384411/10415869 | Lr: 0.00500 | Smooth loss: 21.70330\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5384411/10415869 | Lr: 0.00500 | Smooth loss: 21.70330\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5414575/10415869 | Lr: 0.00500 | Smooth loss: 22.41748\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5414575/10415869 | Lr: 0.00500 | Smooth loss: 22.41748\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5445181/10415869 | Lr: 0.00500 | Smooth loss: 21.87486\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5445181/10415869 | Lr: 0.00500 | Smooth loss: 21.87486\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5475038/10415869 | Lr: 0.00500 | Smooth loss: 21.67578\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5475038/10415869 | Lr: 0.00500 | Smooth loss: 21.67578\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5505381/10415869 | Lr: 0.00500 | Smooth loss: 21.87287\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5505381/10415869 | Lr: 0.00500 | Smooth loss: 21.87287\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5536311/10415869 | Lr: 0.00500 | Smooth loss: 20.76449\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5536311/10415869 | Lr: 0.00500 | Smooth loss: 20.76449\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5566352/10415869 | Lr: 0.00500 | Smooth loss: 21.87797\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5566352/10415869 | Lr: 0.00500 | Smooth loss: 21.87797\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5596953/10415869 | Lr: 0.00500 | Smooth loss: 20.86940\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5596953/10415869 | Lr: 0.00500 | Smooth loss: 20.86940\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5627821/10415869 | Lr: 0.00500 | Smooth loss: 21.54082\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5627821/10415869 | Lr: 0.00500 | Smooth loss: 21.54082\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5657989/10415869 | Lr: 0.00500 | Smooth loss: 21.07636\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5657989/10415869 | Lr: 0.00500 | Smooth loss: 21.07636\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5688290/10415869 | Lr: 0.00500 | Smooth loss: 21.81887\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5688290/10415869 | Lr: 0.00500 | Smooth loss: 21.81887\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5718404/10415869 | Lr: 0.00500 | Smooth loss: 21.34066\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5718404/10415869 | Lr: 0.00500 | Smooth loss: 21.34066\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5747952/10415869 | Lr: 0.00500 | Smooth loss: 21.42286\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5747952/10415869 | Lr: 0.00500 | Smooth loss: 21.42286\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5778834/10415869 | Lr: 0.00500 | Smooth loss: 21.29606\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5778834/10415869 | Lr: 0.00500 | Smooth loss: 21.29606\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5809443/10415869 | Lr: 0.00500 | Smooth loss: 21.03946\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5809443/10415869 | Lr: 0.00500 | Smooth loss: 21.03946\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5839369/10415869 | Lr: 0.00500 | Smooth loss: 22.12556\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5839369/10415869 | Lr: 0.00500 | Smooth loss: 22.12556\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5870454/10415869 | Lr: 0.00500 | Smooth loss: 21.48170\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5870454/10415869 | Lr: 0.00500 | Smooth loss: 21.48170\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5900948/10415869 | Lr: 0.00500 | Smooth loss: 21.36757\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5900948/10415869 | Lr: 0.00500 | Smooth loss: 21.36757\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5930687/10415869 | Lr: 0.00500 | Smooth loss: 22.06265\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5930687/10415869 | Lr: 0.00500 | Smooth loss: 22.06265\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5962281/10415869 | Lr: 0.00500 | Smooth loss: 21.46068\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5962281/10415869 | Lr: 0.00500 | Smooth loss: 21.46068\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 5993093/10415869 | Lr: 0.00500 | Smooth loss: 21.75557\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 5993093/10415869 | Lr: 0.00500 | Smooth loss: 21.75557\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6024212/10415869 | Lr: 0.00500 | Smooth loss: 21.00798\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6024212/10415869 | Lr: 0.00500 | Smooth loss: 21.00798\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6053857/10415869 | Lr: 0.00500 | Smooth loss: 21.75514\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6053857/10415869 | Lr: 0.00500 | Smooth loss: 21.75514\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6084929/10415869 | Lr: 0.00500 | Smooth loss: 22.86171\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6084929/10415869 | Lr: 0.00500 | Smooth loss: 22.86171\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6115715/10415869 | Lr: 0.00500 | Smooth loss: 21.16754\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6115715/10415869 | Lr: 0.00500 | Smooth loss: 21.16754\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6145628/10415869 | Lr: 0.00500 | Smooth loss: 21.09989\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6145628/10415869 | Lr: 0.00500 | Smooth loss: 21.09989\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6175240/10415869 | Lr: 0.00500 | Smooth loss: 21.52710\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6175240/10415869 | Lr: 0.00500 | Smooth loss: 21.52710\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6205998/10415869 | Lr: 0.00500 | Smooth loss: 21.49013\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6205998/10415869 | Lr: 0.00500 | Smooth loss: 21.49013\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6236524/10415869 | Lr: 0.00500 | Smooth loss: 20.99688\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6236524/10415869 | Lr: 0.00500 | Smooth loss: 20.99688\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6267260/10415869 | Lr: 0.00500 | Smooth loss: 21.26726\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6267260/10415869 | Lr: 0.00500 | Smooth loss: 21.26726\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6296647/10415869 | Lr: 0.00500 | Smooth loss: 21.14253\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6296647/10415869 | Lr: 0.00500 | Smooth loss: 21.14253\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6326252/10415869 | Lr: 0.00500 | Smooth loss: 21.85285\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6326252/10415869 | Lr: 0.00500 | Smooth loss: 21.85285\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6357403/10415869 | Lr: 0.00500 | Smooth loss: 21.22719\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6357403/10415869 | Lr: 0.00500 | Smooth loss: 21.22719\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6389066/10415869 | Lr: 0.00500 | Smooth loss: 21.11969\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6389066/10415869 | Lr: 0.00500 | Smooth loss: 21.11969\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6419340/10415869 | Lr: 0.00500 | Smooth loss: 21.17906\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6419340/10415869 | Lr: 0.00500 | Smooth loss: 21.17906\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6450458/10415869 | Lr: 0.00500 | Smooth loss: 22.03416\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6450458/10415869 | Lr: 0.00500 | Smooth loss: 22.03416\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6481196/10415869 | Lr: 0.00500 | Smooth loss: 20.77004\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6481196/10415869 | Lr: 0.00500 | Smooth loss: 20.77004\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6510540/10415869 | Lr: 0.00500 | Smooth loss: 21.33683\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6510540/10415869 | Lr: 0.00500 | Smooth loss: 21.33683\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6539867/10415869 | Lr: 0.00500 | Smooth loss: 21.09893\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6539867/10415869 | Lr: 0.00500 | Smooth loss: 21.09893\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6570361/10415869 | Lr: 0.00500 | Smooth loss: 21.85878\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6570361/10415869 | Lr: 0.00500 | Smooth loss: 21.85878\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6600814/10415869 | Lr: 0.00500 | Smooth loss: 20.96757\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6600814/10415869 | Lr: 0.00500 | Smooth loss: 20.96757\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6630914/10415869 | Lr: 0.00500 | Smooth loss: 20.82038\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6630914/10415869 | Lr: 0.00500 | Smooth loss: 20.82038\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6661728/10415869 | Lr: 0.00500 | Smooth loss: 21.82320\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6661728/10415869 | Lr: 0.00500 | Smooth loss: 21.82320\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6692002/10415869 | Lr: 0.00500 | Smooth loss: 20.86687\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6692002/10415869 | Lr: 0.00500 | Smooth loss: 20.86687\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6722053/10415869 | Lr: 0.00500 | Smooth loss: 20.77309\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6722053/10415869 | Lr: 0.00500 | Smooth loss: 20.77309\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6751982/10415869 | Lr: 0.00500 | Smooth loss: 21.16108\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6751982/10415869 | Lr: 0.00500 | Smooth loss: 21.16108\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6782769/10415869 | Lr: 0.00500 | Smooth loss: 21.57112\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6782769/10415869 | Lr: 0.00500 | Smooth loss: 21.57112\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6812495/10415869 | Lr: 0.00500 | Smooth loss: 20.93825\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6812495/10415869 | Lr: 0.00500 | Smooth loss: 20.93825\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6843272/10415869 | Lr: 0.00500 | Smooth loss: 20.76990\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6843272/10415869 | Lr: 0.00500 | Smooth loss: 20.76990\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6873191/10415869 | Lr: 0.00500 | Smooth loss: 21.15622\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6873191/10415869 | Lr: 0.00500 | Smooth loss: 21.15622\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6903751/10415869 | Lr: 0.00500 | Smooth loss: 21.68057\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6903751/10415869 | Lr: 0.00500 | Smooth loss: 21.68057\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6933297/10415869 | Lr: 0.00500 | Smooth loss: 20.50206\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6933297/10415869 | Lr: 0.00500 | Smooth loss: 20.50206\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6964651/10415869 | Lr: 0.00500 | Smooth loss: 21.75423\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6964651/10415869 | Lr: 0.00500 | Smooth loss: 21.75423\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 6994234/10415869 | Lr: 0.00500 | Smooth loss: 20.84549\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 6994234/10415869 | Lr: 0.00500 | Smooth loss: 20.84549\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7023729/10415869 | Lr: 0.00500 | Smooth loss: 21.11085\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7023729/10415869 | Lr: 0.00500 | Smooth loss: 21.11085\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7054652/10415869 | Lr: 0.00500 | Smooth loss: 21.78529\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7054652/10415869 | Lr: 0.00500 | Smooth loss: 21.78529\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7085376/10415869 | Lr: 0.00500 | Smooth loss: 21.32154\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7085376/10415869 | Lr: 0.00500 | Smooth loss: 21.32154\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7115661/10415869 | Lr: 0.00500 | Smooth loss: 21.82323\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7115661/10415869 | Lr: 0.00500 | Smooth loss: 21.82323\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7145620/10415869 | Lr: 0.00500 | Smooth loss: 21.22895\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7145620/10415869 | Lr: 0.00500 | Smooth loss: 21.22895\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7176309/10415869 | Lr: 0.00500 | Smooth loss: 20.63582\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7176309/10415869 | Lr: 0.00500 | Smooth loss: 20.63582\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7207362/10415869 | Lr: 0.00500 | Smooth loss: 21.11330\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7207362/10415869 | Lr: 0.00500 | Smooth loss: 21.11330\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7237073/10415869 | Lr: 0.00500 | Smooth loss: 20.97355\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7237073/10415869 | Lr: 0.00500 | Smooth loss: 20.97355\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7268071/10415869 | Lr: 0.00500 | Smooth loss: 21.18874\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7268071/10415869 | Lr: 0.00500 | Smooth loss: 21.18874\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7298417/10415869 | Lr: 0.00500 | Smooth loss: 20.17320\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7298417/10415869 | Lr: 0.00500 | Smooth loss: 20.17320\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7328048/10415869 | Lr: 0.00500 | Smooth loss: 20.01964\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7328048/10415869 | Lr: 0.00500 | Smooth loss: 20.01964\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7358492/10415869 | Lr: 0.00500 | Smooth loss: 21.06789\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7358492/10415869 | Lr: 0.00500 | Smooth loss: 21.06789\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7389557/10415869 | Lr: 0.00500 | Smooth loss: 20.84957\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7389557/10415869 | Lr: 0.00500 | Smooth loss: 20.84957\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7418052/10415869 | Lr: 0.00500 | Smooth loss: 20.10217\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7418052/10415869 | Lr: 0.00500 | Smooth loss: 20.10217\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7448201/10415869 | Lr: 0.00500 | Smooth loss: 21.34196\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7448201/10415869 | Lr: 0.00500 | Smooth loss: 21.34196\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7477328/10415869 | Lr: 0.00500 | Smooth loss: 20.46366\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7477328/10415869 | Lr: 0.00500 | Smooth loss: 20.46366\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7508236/10415869 | Lr: 0.00500 | Smooth loss: 20.40384\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7508236/10415869 | Lr: 0.00500 | Smooth loss: 20.40384\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7538005/10415869 | Lr: 0.00500 | Smooth loss: 20.54750\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7538005/10415869 | Lr: 0.00500 | Smooth loss: 20.54750\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7568515/10415869 | Lr: 0.00500 | Smooth loss: 20.32700\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7568515/10415869 | Lr: 0.00500 | Smooth loss: 20.32700\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7598198/10415869 | Lr: 0.00500 | Smooth loss: 20.78336\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7598198/10415869 | Lr: 0.00500 | Smooth loss: 20.78336\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7627506/10415869 | Lr: 0.00500 | Smooth loss: 20.38460\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7627506/10415869 | Lr: 0.00500 | Smooth loss: 20.38460\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7657848/10415869 | Lr: 0.00500 | Smooth loss: 20.24733\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7657848/10415869 | Lr: 0.00500 | Smooth loss: 20.24733\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7688055/10415869 | Lr: 0.00500 | Smooth loss: 20.62920\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7688055/10415869 | Lr: 0.00500 | Smooth loss: 20.62920\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7717907/10415869 | Lr: 0.00500 | Smooth loss: 20.31355\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7717907/10415869 | Lr: 0.00500 | Smooth loss: 20.31355\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7748792/10415869 | Lr: 0.00500 | Smooth loss: 20.15316\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7748792/10415869 | Lr: 0.00500 | Smooth loss: 20.15316\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7778072/10415869 | Lr: 0.00500 | Smooth loss: 20.32359\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7778072/10415869 | Lr: 0.00500 | Smooth loss: 20.32359\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7807719/10415869 | Lr: 0.00500 | Smooth loss: 20.82824\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7807719/10415869 | Lr: 0.00500 | Smooth loss: 20.82824\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7837203/10415869 | Lr: 0.00500 | Smooth loss: 20.34269\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7837203/10415869 | Lr: 0.00500 | Smooth loss: 20.34269\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7868722/10415869 | Lr: 0.00500 | Smooth loss: 20.78409\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7868722/10415869 | Lr: 0.00500 | Smooth loss: 20.78409\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7897925/10415869 | Lr: 0.00500 | Smooth loss: 20.04748\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7897925/10415869 | Lr: 0.00500 | Smooth loss: 20.04748\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7928020/10415869 | Lr: 0.00500 | Smooth loss: 19.76769\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7928020/10415869 | Lr: 0.00500 | Smooth loss: 19.76769\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7959457/10415869 | Lr: 0.00500 | Smooth loss: 20.78603\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7959457/10415869 | Lr: 0.00500 | Smooth loss: 20.78603\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 7989482/10415869 | Lr: 0.00500 | Smooth loss: 21.04880\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 7989482/10415869 | Lr: 0.00500 | Smooth loss: 21.04880\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8019349/10415869 | Lr: 0.00500 | Smooth loss: 20.08553\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8019349/10415869 | Lr: 0.00500 | Smooth loss: 20.08553\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8050270/10415869 | Lr: 0.00500 | Smooth loss: 20.67500\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8050270/10415869 | Lr: 0.00500 | Smooth loss: 20.67500\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8080261/10415869 | Lr: 0.00500 | Smooth loss: 20.55014\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8080261/10415869 | Lr: 0.00500 | Smooth loss: 20.55014\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8110761/10415869 | Lr: 0.00500 | Smooth loss: 20.25557\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8110761/10415869 | Lr: 0.00500 | Smooth loss: 20.25557\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8140689/10415869 | Lr: 0.00500 | Smooth loss: 19.72446\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8140689/10415869 | Lr: 0.00500 | Smooth loss: 19.72446\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8171418/10415869 | Lr: 0.00500 | Smooth loss: 19.49484\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8171418/10415869 | Lr: 0.00500 | Smooth loss: 19.49484\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8201032/10415869 | Lr: 0.00500 | Smooth loss: 20.93963\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8201032/10415869 | Lr: 0.00500 | Smooth loss: 20.93963\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8230531/10415869 | Lr: 0.00500 | Smooth loss: 20.68070\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8230531/10415869 | Lr: 0.00500 | Smooth loss: 20.68070\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8261230/10415869 | Lr: 0.00500 | Smooth loss: 20.75471\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8261230/10415869 | Lr: 0.00500 | Smooth loss: 20.75471\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8291511/10415869 | Lr: 0.00500 | Smooth loss: 20.74062\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8291511/10415869 | Lr: 0.00500 | Smooth loss: 20.74062\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8322072/10415869 | Lr: 0.00500 | Smooth loss: 20.52622\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8322072/10415869 | Lr: 0.00500 | Smooth loss: 20.52622\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8351877/10415869 | Lr: 0.00500 | Smooth loss: 19.97136\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8351877/10415869 | Lr: 0.00500 | Smooth loss: 19.97136\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8381851/10415869 | Lr: 0.00500 | Smooth loss: 20.22646\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8381851/10415869 | Lr: 0.00500 | Smooth loss: 20.22646\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8412692/10415869 | Lr: 0.00500 | Smooth loss: 20.52703\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8412692/10415869 | Lr: 0.00500 | Smooth loss: 20.52703\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8443718/10415869 | Lr: 0.00500 | Smooth loss: 20.61996\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8443718/10415869 | Lr: 0.00500 | Smooth loss: 20.61996\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8473179/10415869 | Lr: 0.00500 | Smooth loss: 20.06840\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8473179/10415869 | Lr: 0.00500 | Smooth loss: 20.06840\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8504859/10415869 | Lr: 0.00500 | Smooth loss: 20.98943\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8504859/10415869 | Lr: 0.00500 | Smooth loss: 20.98943\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8535730/10415869 | Lr: 0.00500 | Smooth loss: 20.64365\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8535730/10415869 | Lr: 0.00500 | Smooth loss: 20.64365\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8566080/10415869 | Lr: 0.00500 | Smooth loss: 20.20016\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8566080/10415869 | Lr: 0.00500 | Smooth loss: 20.20016\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8596857/10415869 | Lr: 0.00500 | Smooth loss: 20.15176\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8596857/10415869 | Lr: 0.00500 | Smooth loss: 20.15176\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8625565/10415869 | Lr: 0.00500 | Smooth loss: 19.51953\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8625565/10415869 | Lr: 0.00500 | Smooth loss: 19.51953\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8656506/10415869 | Lr: 0.00500 | Smooth loss: 20.26870\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8656506/10415869 | Lr: 0.00500 | Smooth loss: 20.26870\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8686246/10415869 | Lr: 0.00500 | Smooth loss: 19.78318\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8686246/10415869 | Lr: 0.00500 | Smooth loss: 19.78318\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8715008/10415869 | Lr: 0.00500 | Smooth loss: 20.36747\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8715008/10415869 | Lr: 0.00500 | Smooth loss: 20.36747\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8746013/10415869 | Lr: 0.00500 | Smooth loss: 20.14539\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8746013/10415869 | Lr: 0.00500 | Smooth loss: 20.14539\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8777021/10415869 | Lr: 0.00500 | Smooth loss: 20.16809\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8777021/10415869 | Lr: 0.00500 | Smooth loss: 20.16809\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8806984/10415869 | Lr: 0.00500 | Smooth loss: 20.15693\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8806984/10415869 | Lr: 0.00500 | Smooth loss: 20.15693\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8837094/10415869 | Lr: 0.00500 | Smooth loss: 20.02831\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8837094/10415869 | Lr: 0.00500 | Smooth loss: 20.02831\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8866874/10415869 | Lr: 0.00500 | Smooth loss: 19.73860\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8866874/10415869 | Lr: 0.00500 | Smooth loss: 19.73860\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8897051/10415869 | Lr: 0.00500 | Smooth loss: 20.57770\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8897051/10415869 | Lr: 0.00500 | Smooth loss: 20.57770\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8928387/10415869 | Lr: 0.00500 | Smooth loss: 20.29105\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8928387/10415869 | Lr: 0.00500 | Smooth loss: 20.29105\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8959133/10415869 | Lr: 0.00500 | Smooth loss: 19.87063\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8959133/10415869 | Lr: 0.00500 | Smooth loss: 19.87063\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 8989020/10415869 | Lr: 0.00500 | Smooth loss: 19.87941\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 8989020/10415869 | Lr: 0.00500 | Smooth loss: 19.87941\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9018726/10415869 | Lr: 0.00500 | Smooth loss: 19.88233\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9018726/10415869 | Lr: 0.00500 | Smooth loss: 19.88233\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9049447/10415869 | Lr: 0.00500 | Smooth loss: 19.99034\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9049447/10415869 | Lr: 0.00500 | Smooth loss: 19.99034\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9080791/10415869 | Lr: 0.00500 | Smooth loss: 20.42051\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9080791/10415869 | Lr: 0.00500 | Smooth loss: 20.42051\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9110118/10415869 | Lr: 0.00500 | Smooth loss: 19.37163\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9110118/10415869 | Lr: 0.00500 | Smooth loss: 19.37163\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9140656/10415869 | Lr: 0.00500 | Smooth loss: 19.60168\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9140656/10415869 | Lr: 0.00500 | Smooth loss: 19.60168\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9171045/10415869 | Lr: 0.00500 | Smooth loss: 20.68077\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9171045/10415869 | Lr: 0.00500 | Smooth loss: 20.68077\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9202417/10415869 | Lr: 0.00500 | Smooth loss: 20.31201\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9202417/10415869 | Lr: 0.00500 | Smooth loss: 20.31201\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9231643/10415869 | Lr: 0.00500 | Smooth loss: 19.78776\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9231643/10415869 | Lr: 0.00500 | Smooth loss: 19.78776\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9261245/10415869 | Lr: 0.00500 | Smooth loss: 19.79687\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9261245/10415869 | Lr: 0.00500 | Smooth loss: 19.79687\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9290369/10415869 | Lr: 0.00500 | Smooth loss: 19.06492\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9290369/10415869 | Lr: 0.00500 | Smooth loss: 19.06492\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9321889/10415869 | Lr: 0.00500 | Smooth loss: 20.05827\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9321889/10415869 | Lr: 0.00500 | Smooth loss: 20.05827\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9352183/10415869 | Lr: 0.00500 | Smooth loss: 19.76228\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9352183/10415869 | Lr: 0.00500 | Smooth loss: 19.76228\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9382506/10415869 | Lr: 0.00500 | Smooth loss: 19.25472\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9382506/10415869 | Lr: 0.00500 | Smooth loss: 19.25472\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9414163/10415869 | Lr: 0.00500 | Smooth loss: 20.15795\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9414163/10415869 | Lr: 0.00500 | Smooth loss: 20.15795\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9445351/10415869 | Lr: 0.00500 | Smooth loss: 19.85481\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9445351/10415869 | Lr: 0.00500 | Smooth loss: 19.85481\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9475228/10415869 | Lr: 0.00500 | Smooth loss: 20.16974\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9475228/10415869 | Lr: 0.00500 | Smooth loss: 20.16974\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9505930/10415869 | Lr: 0.00500 | Smooth loss: 19.50676\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9505930/10415869 | Lr: 0.00500 | Smooth loss: 19.50676\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9536912/10415869 | Lr: 0.00500 | Smooth loss: 19.40733\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9536912/10415869 | Lr: 0.00500 | Smooth loss: 19.40733\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9568486/10415869 | Lr: 0.00500 | Smooth loss: 19.48854\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9568486/10415869 | Lr: 0.00500 | Smooth loss: 19.48854\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9598370/10415869 | Lr: 0.00500 | Smooth loss: 20.00968\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9598370/10415869 | Lr: 0.00500 | Smooth loss: 20.00968\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9629628/10415869 | Lr: 0.00500 | Smooth loss: 20.03497\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9629628/10415869 | Lr: 0.00500 | Smooth loss: 20.03497\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9659034/10415869 | Lr: 0.00500 | Smooth loss: 19.21387\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9659034/10415869 | Lr: 0.00500 | Smooth loss: 19.21387\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9688787/10415869 | Lr: 0.00500 | Smooth loss: 19.41610\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9688787/10415869 | Lr: 0.00500 | Smooth loss: 19.41610\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9719648/10415869 | Lr: 0.00500 | Smooth loss: 19.54018\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9719648/10415869 | Lr: 0.00500 | Smooth loss: 19.54018\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9748665/10415869 | Lr: 0.00500 | Smooth loss: 19.33853\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9748665/10415869 | Lr: 0.00500 | Smooth loss: 19.33853\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9779672/10415869 | Lr: 0.00500 | Smooth loss: 19.81659\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9779672/10415869 | Lr: 0.00500 | Smooth loss: 19.81659\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9809874/10415869 | Lr: 0.00500 | Smooth loss: 19.87233\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9809874/10415869 | Lr: 0.00500 | Smooth loss: 19.87233\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9839095/10415869 | Lr: 0.00500 | Smooth loss: 19.17354\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9839095/10415869 | Lr: 0.00500 | Smooth loss: 19.17354\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9868953/10415869 | Lr: 0.00500 | Smooth loss: 19.55288\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9868953/10415869 | Lr: 0.00500 | Smooth loss: 19.55288\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9898861/10415869 | Lr: 0.00500 | Smooth loss: 19.36371\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9898861/10415869 | Lr: 0.00500 | Smooth loss: 19.36371\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9928849/10415869 | Lr: 0.00500 | Smooth loss: 20.02167\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9928849/10415869 | Lr: 0.00500 | Smooth loss: 20.02167\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9959675/10415869 | Lr: 0.00500 | Smooth loss: 19.67631\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9959675/10415869 | Lr: 0.00500 | Smooth loss: 19.67631\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 9989882/10415869 | Lr: 0.00500 | Smooth loss: 19.72635\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 9989882/10415869 | Lr: 0.00500 | Smooth loss: 19.72635\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 10020265/10415869 | Lr: 0.00500 | Smooth loss: 19.29527\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 10020265/10415869 | Lr: 0.00500 | Smooth loss: 19.29527\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 10051853/10415869 | Lr: 0.00500 | Smooth loss: 20.16180\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 10051853/10415869 | Lr: 0.00500 | Smooth loss: 20.16180\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 10081426/10415869 | Lr: 0.00500 | Smooth loss: 20.22074\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 10081426/10415869 | Lr: 0.00500 | Smooth loss: 20.22074\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 10111647/10415869 | Lr: 0.00500 | Smooth loss: 19.44695\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 10111647/10415869 | Lr: 0.00500 | Smooth loss: 19.44695\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 10141950/10415869 | Lr: 0.00500 | Smooth loss: 19.91254\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 10141950/10415869 | Lr: 0.00500 | Smooth loss: 19.91254\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 10172811/10415869 | Lr: 0.00500 | Smooth loss: 19.57187\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 10172811/10415869 | Lr: 0.00500 | Smooth loss: 19.57187\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 10202819/10415869 | Lr: 0.00500 | Smooth loss: 19.06824\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 10202819/10415869 | Lr: 0.00500 | Smooth loss: 19.06824\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 10233567/10415869 | Lr: 0.00500 | Smooth loss: 19.72686\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 10233567/10415869 | Lr: 0.00500 | Smooth loss: 19.72686\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 10264426/10415869 | Lr: 0.00500 | Smooth loss: 19.64467\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 10264426/10415869 | Lr: 0.00500 | Smooth loss: 19.64467\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 10294709/10415869 | Lr: 0.00500 | Smooth loss: 19.70113\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 10294709/10415869 | Lr: 0.00500 | Smooth loss: 19.70113\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 10325697/10415869 | Lr: 0.00500 | Smooth loss: 19.23922\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 10325697/10415869 | Lr: 0.00500 | Smooth loss: 19.23922\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 10355567/10415869 | Lr: 0.00500 | Smooth loss: 19.62361\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 10355567/10415869 | Lr: 0.00500 | Smooth loss: 19.62361\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Epoch: 01 | Words: 10386582/10415869 | Lr: 0.00500 | Smooth loss: 19.67828\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_transe_model/train_log.txt:Epoch: 01 | Words: 10386582/10415869 | Lr: 0.00500 | Smooth loss: 19.67828\n"]},{"output_type":"stream","name":"stdout","text":["Load embeddings ./tmp/Challenge_Dataset/train_transe_model/transe_model_sd_epoch_1.ckpt\n"]}],"source":["logger = None\n","convergence = 0\n","smooth_loss_min = 0\n","\n","\n","def train(dataset='challenge',name='train_transe_model',log_dir = './', device='cuda',seed=123,gpu='0',epochs=1, batch_size=64,lr=0.5,weight_decay=0,l2_lambda=0,max_grad_norm=5.0,embed_size=300,num_neg_samples=5,steps_per_checkpoint=200):\n","    data = load_dataset(dataset)\n","    dataloader = ChallengeDataLoader(data, batch_size)\n","    words_to_train = epochs * data.text.word_count + 1\n","\n","    model = KnowledgeEmbedding(data, device=device,seed=123,gpu='0',epochs=1, batch_size=64,lr=0.5,weight_decay=0,l2_lambda=0,max_grad_norm=5.0,embed_size=300,num_neg_samples=5,steps_per_checkpoint=200).to(device)\n","     #logger.info('Parameters:' + str([i[0] for i in model.named_parameters()]))\n","    optimizer = optim.SGD(model.parameters(), lr=lr)\n","    steps = 0\n","    smooth_loss = 0.0\n","\n","    for epoch in range(1, epochs + 1):\n","        dataloader.reset()\n","        while dataloader.has_next():\n","            # Set learning rate.\n","            #lr = lr * max(1e-4, 1.0 - dataloader.finished_word_num / float(words_to_train))\n","            for pg in optimizer.param_groups:\n","                pg['lr'] = lr\n","\n","            # Get training batch.\n","            batch_idxs = dataloader.get_batch()\n","            batch_idxs = torch.from_numpy(batch_idxs).to(device)\n","\n","            # Train model.\n","            optimizer.zero_grad()\n","            train_loss = model(batch_idxs)\n","            train_loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n","            optimizer.step()\n","            smooth_loss += train_loss.item() / steps_per_checkpoint\n","\n","            steps += 1\n","            if steps % steps_per_checkpoint == 0:\n","                logger.info('Epoch: {:02d} | '.format(epoch) +\n","                            'Words: {:d}/{:d} | '.format(dataloader.finished_word_num, words_to_train) +\n","                            'Lr: {:.5f} | '.format(lr) +\n","                            'Smooth loss: {:.5f}'.format(smooth_loss))\n","                smooth_loss = 0.0\n","\n","        torch.save(model.state_dict(), '{}/transe_model_sd_epoch_{}.ckpt'.format(log_dir, epoch))\n","\n","\n","def extract_embeddings(dataset='challenge',name='train_transe_model',log_dir='./', seed=123,gpu='0',epochs=1, batch_size=64,lr=0.5,weight_decay=0,l2_lambda=0,max_grad_norm=5.0,embed_size=300,num_neg_samples=5,steps_per_checkpoint=200):\n","    \"\"\"Note that last entity embedding is of size [vocab_size+1, d].\"\"\"\n","    model_file = '{}/transe_model_sd_epoch_{}.ckpt'.format(log_dir, epochs)\n","    print('Load embeddings', model_file)\n","    state_dict = torch.load(model_file, map_location=lambda storage, loc: storage)\n","    embeds = {\n","        USER: state_dict['user.weight'].cpu().data.numpy()[:-1],  # Must remove last dummy 'user' with 0 embed.\n","        ARTICLE: state_dict['article.weight'].cpu().data.numpy()[:-1],\n","        WORD: state_dict['word.weight'].cpu().data.numpy()[:-1],\n","        TOPIC: state_dict['topic.weight'].cpu().data.numpy()[:-1],\n","        PRODUCT: state_dict['product.weight'].cpu().data.numpy()[:-1],\n","        RARTICLE: state_dict['related_article.weight'].cpu().data.numpy()[:-1],\n","        TOPIC_TAG: state_dict['topic_tag.weight'].cpu().data.numpy()[:-1],\n","        PRODUCT_TAG: state_dict['product_tag.weight'].cpu().data.numpy()[:-1],\n","\n","        RECOMMENDED: (\n","            state_dict['recommended'].cpu().data.numpy()[0],\n","            state_dict['recommended_bias.weight'].cpu().data.numpy()\n","        ),\n","        WITHIN: (\n","            state_dict['within'].cpu().data.numpy()[0],\n","            state_dict['within_bias.weight'].cpu().data.numpy()\n","        ),\n","        HAS_TOPIC: (\n","            state_dict['has_topic'].cpu().data.numpy()[0],\n","            state_dict['has_topic_bias.weight'].cpu().data.numpy()\n","        ),\n","        HAS_PRODUCT: (\n","            state_dict['has_product'].cpu().data.numpy()[0],\n","            state_dict['has_product_bias.weight'].cpu().data.numpy()\n","        ),\n","        HAS_TOPIC_TAG: (\n","            state_dict['has_topic_tag'].cpu().data.numpy()[0],\n","            state_dict['has_topic_tag_bias.weight'].cpu().data.numpy()\n","        ),\n","        HAS_PRODUCT_TAG: (\n","            state_dict['has_product_tag'].cpu().data.numpy()[0],\n","            state_dict['has_product_tag_bias.weight'].cpu().data.numpy()\n","        ),\n","        ALSO_RESPONSE: (\n","            state_dict['also_response'].cpu().data.numpy()[0],\n","            state_dict['also_response_bias.weight'].cpu().data.numpy()\n","        ),\n","        RECOMMENDED_TOGETHER: (\n","            state_dict['recommended_together'].cpu().data.numpy()[0],\n","            state_dict['recommended_together_bias.weight'].cpu().data.numpy()\n","        ),\n","        RESPONSE_TOGETHER: (\n","            state_dict['response_together'].cpu().data.numpy()[0],\n","            state_dict['response_together_bias.weight'].cpu().data.numpy()\n","        ),\n","    }\n","    save_embed(dataset, embeds)\n","\n","\n","def main(dataset='challenge',name='train_transe_model',seed=123,gpu='0',epochs=1, batch_size=64,lr=0.5,weight_decay=0,l2_lambda=0,max_grad_norm=5.0,embed_size=300,num_neg_samples=5,steps_per_checkpoint=200):\n","\n","    os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n","    device = torch.device('cuda:0') if torch.cuda.is_available() else 'cpu'\n","\n","    log_dir = '{}/{}'.format(TMP_DIR[dataset], name)\n","    print(log_dir)\n","    if not os.path.isdir(log_dir):\n","        os.makedirs(log_dir)\n","\n","    global logger\n","    logger = get_logger(log_dir + '/train_log.txt')\n","    set_random_seed(seed)\n","    train(dataset='challenge',name='train_transe_model',log_dir= '{}/{}'.format(TMP_DIR[dataset], name),device=device,seed=123,gpu='0',epochs=1, batch_size=64,lr=0.005,weight_decay=0,l2_lambda=0,max_grad_norm=5.0,embed_size=300,num_neg_samples=5,steps_per_checkpoint=200)\n","    extract_embeddings(dataset='challenge',name='train_transe_model',log_dir=log_dir, seed=123,gpu='0',epochs=1, batch_size=64,lr=0.005,weight_decay=0,l2_lambda=0,max_grad_norm=5.0,embed_size=300,num_neg_samples=5,steps_per_checkpoint=200)\n","\n","\n","if __name__ == '__main__':\n","    main(dataset='challenge',name='train_transe_model',seed=123,gpu='0',epochs=1, batch_size=64,lr=0.005,weight_decay=0,l2_lambda=0,max_grad_norm=5.0,embed_size=300,num_neg_samples=5,steps_per_checkpoint=200)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"ZEr-pltWnF41","executionInfo":{"status":"ok","timestamp":1689085834735,"user_tz":-60,"elapsed":318,"user":{"displayName":"huan chen","userId":"01704466685251061733"}}},"outputs":[],"source":["import argparse\n","from collections import namedtuple\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.autograd import Variable\n","from torch.distributions import Categorical\n","\n","from kg_env import BatchKGEnvironment"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nawYuQv1nF42","executionInfo":{"status":"ok","timestamp":1689085840012,"user_tz":-60,"elapsed":2671,"user":{"displayName":"huan chen","userId":"01704466685251061733"}},"outputId":"3d3d8472-3407-4cf5-9bd0-8d5230ab0dc5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Load embedding: ./tmp/Challenge_Dataset/transe_embed.pkl\n","[INFO]  Parameters:['l1.weight', 'l1.bias', 'l2.weight', 'l2.bias', 'actor.weight', 'actor.bias', 'critic.weight', 'critic.bias']\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_agent/train_log.txt:Parameters:['l1.weight', 'l1.bias', 'l2.weight', 'l2.bias', 'actor.weight', 'actor.bias', 'critic.weight', 'critic.bias']\n","<ipython-input-9-f55a25594160>:29: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at ../aten/src/ATen/native/cuda/Indexing.cu:1440.)\n","  actor_logits[1 - act_mask] = -999999.0\n","/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py:200: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at ../aten/src/ATen/native/cuda/Indexing.cu:1440.)\n","  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]  Save model to ./tmp/Challenge_Dataset/train_agent/policy_model_epoch_1.ckpt\n"]},{"output_type":"stream","name":"stderr","text":["INFO:./tmp/Challenge_Dataset/train_agent/train_log.txt:Save model to ./tmp/Challenge_Dataset/train_agent/policy_model_epoch_1.ckpt\n"]}],"source":["logger = None\n","\n","SavedAction = namedtuple('SavedAction', ['log_prob', 'value'])\n","\n","class ActorCritic(nn.Module):\n","    def __init__(self, state_dim, act_dim, gamma=0.99, hidden_sizes=[512, 256]):\n","        super(ActorCritic, self).__init__()\n","        self.state_dim = state_dim\n","        self.act_dim = act_dim\n","        self.gamma = gamma\n","\n","        self.l1 = nn.Linear(state_dim, hidden_sizes[0])\n","        self.l2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n","        self.actor = nn.Linear(hidden_sizes[1], act_dim)\n","        self.critic = nn.Linear(hidden_sizes[1], 1)\n","\n","        self.saved_actions = []\n","        self.rewards = []\n","        self.entropy = []\n","\n","    def forward(self, inputs):\n","        state, act_mask = inputs  # state: [bs, state_dim], act_mask: [bs, act_dim]\n","        x = self.l1(state)\n","        x = F.dropout(F.elu(x), p=0.5)\n","        out = self.l2(x)\n","        x = F.dropout(F.elu(out), p=0.5)\n","\n","        actor_logits = self.actor(x)\n","        actor_logits[1 - act_mask] = -999999.0\n","        act_probs = F.softmax(actor_logits, dim=-1)  # Tensor of [bs, act_dim]\n","\n","        state_values = self.critic(x)  # Tensor of [bs, 1]\n","        return act_probs, state_values\n","\n","    def select_action(self, batch_state, batch_act_mask, device):\n","        state = torch.FloatTensor(batch_state).to(device)  # Tensor [bs, state_dim]\n","        act_mask = torch.ByteTensor(batch_act_mask).to(device)  # Tensor of [bs, act_dim]\n","\n","        probs, value = self((state, act_mask))  # act_probs: [bs, act_dim], state_value: [bs, 1]\n","        m = Categorical(probs)\n","        acts = m.sample()  # Tensor of [bs, ], requires_grad=False\n","        # [CAVEAT] If sampled action is out of action_space, choose the first action in action_space.\n","        valid_idx = act_mask.gather(1, acts.view(-1, 1)).view(-1)\n","        acts[valid_idx == 0] = 0\n","\n","        self.saved_actions.append(SavedAction(m.log_prob(acts), value))\n","        self.entropy.append(m.entropy())\n","        return acts.cpu().numpy().tolist()\n","\n","    def update(self, optimizer, device, ent_weight):\n","        if len(self.rewards) <= 0:\n","            del self.rewards[:]\n","            del self.saved_actions[:]\n","            del self.entropy[:]\n","            return 0.0, 0.0, 0.0\n","\n","        batch_rewards = np.vstack(self.rewards).T  # numpy array of [bs, #steps]\n","        batch_rewards = torch.FloatTensor(batch_rewards).to(device)\n","        num_steps = batch_rewards.shape[1]\n","        for i in range(1, num_steps):\n","            batch_rewards[:, num_steps - i - 1] += self.gamma * batch_rewards[:, num_steps - i]\n","\n","        actor_loss = 0\n","        critic_loss = 0\n","        entropy_loss = 0\n","        for i in range(0, num_steps):\n","            log_prob, value = self.saved_actions[i]  # log_prob: Tensor of [bs, ], value: Tensor of [bs, 1]\n","            advantage = batch_rewards[:, i] - value.squeeze(1)  # Tensor of [bs, ]\n","            actor_loss += -log_prob * advantage.detach()  # Tensor of [bs, ]\n","            critic_loss += advantage.pow(2)  # Tensor of [bs, ]\n","            entropy_loss += -self.entropy[i]  # Tensor of [bs, ]\n","        actor_loss = actor_loss.mean()\n","        critic_loss = critic_loss.mean()\n","        entropy_loss = entropy_loss.mean()\n","        loss = actor_loss + critic_loss + ent_weight * entropy_loss\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        del self.rewards[:]\n","        del self.saved_actions[:]\n","        del self.entropy[:]\n","\n","        return loss.item(), actor_loss.item(), critic_loss.item(), entropy_loss.item()\n","\n","\n","class ACDataLoader(object):\n","    def __init__(self, uids, batch_size):\n","        self.uids = np.array(uids)\n","        self.num_users = len(uids)\n","        self.batch_size = batch_size\n","        self.reset()\n","\n","    def reset(self):\n","        self._rand_perm = np.random.permutation(self.num_users)\n","        self._start_idx = 0\n","        self._has_next = True\n","\n","    def has_next(self):\n","        return self._has_next\n","\n","    def get_batch(self):\n","        if not self._has_next:\n","            return None\n","        # Multiple users per batch\n","        end_idx = min(self._start_idx + self.batch_size, self.num_users)\n","        batch_idx = self._rand_perm[self._start_idx:end_idx]\n","        batch_uids = self.uids[batch_idx]\n","        self._has_next = self._has_next and end_idx < self.num_users\n","        self._start_idx = end_idx\n","        return batch_uids.tolist()\n","\n","\n","def train( dataset='challenge',name='train_agent',seed=123,gpu='0',epochs=1, batch_size=32,lr=1e-4,max_acts=250,max_path_len=3,\n","    gamma=0.99,ent_weight=1e-3,act_dropout=0.5,state_history=1,hidden=[512, 256],device='cuda',log_dir='./'):\n","    env = BatchKGEnvironment(dataset, max_acts, max_path_len=max_path_len, state_history=state_history)\n","    uids = list(env.kg(USER).keys())\n","    dataloader = ACDataLoader(uids, batch_size)\n","    model = ActorCritic(env.state_dim, env.act_dim, gamma=gamma, hidden_sizes=hidden).to(device)\n","    logger.info('Parameters:' + str([i[0] for i in model.named_parameters()]))\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","\n","    total_losses, total_plosses, total_vlosses, total_entropy, total_rewards = [], [], [], [], []\n","    step = 0\n","    model.train()\n","    for epoch in range(1, epochs + 1):\n","        ### Start epoch ###\n","        dataloader.reset()\n","        while dataloader.has_next():\n","            batch_uids = dataloader.get_batch()\n","            ### Start batch episodes ###\n","            batch_state = env.reset(batch_uids)  # numpy array of [bs, state_dim]\n","            done = False\n","            while not done:\n","                batch_act_mask = env.batch_action_mask(dropout=act_dropout)  # numpy array of size [bs, act_dim]\n","                batch_act_idx = model.select_action(batch_state, batch_act_mask, device)  # int\n","                batch_state, batch_reward, done = env.batch_step(batch_act_idx)\n","                model.rewards.append(batch_reward)\n","            ### End of episodes ###\n","\n","            lr_e = lr * max(1e-4, 1.0 - float(step) / (epochs * len(uids) / batch_size))\n","            for pg in optimizer.param_groups:\n","                pg['lr'] = lr_e\n","\n","            # Update policy\n","            total_rewards.append(np.sum(model.rewards))\n","            loss, ploss, vloss, eloss = model.update(optimizer, device, ent_weight)\n","            total_losses.append(loss)\n","            total_plosses.append(ploss)\n","            total_vlosses.append(vloss)\n","            total_entropy.append(eloss)\n","            step += 1\n","\n","            # Report performance\n","            if step > 0 and step % 100 == 0:\n","                avg_reward = np.mean(total_rewards) / batch_size\n","                avg_loss = np.mean(total_losses)\n","                avg_ploss = np.mean(total_plosses)\n","                avg_vloss = np.mean(total_vlosses)\n","                avg_entropy = np.mean(total_entropy)\n","                total_losses, total_plosses, total_vlosses, total_entropy, total_rewards = [], [], [], [], []\n","                logger.info(\n","                        'epoch/step={:d}/{:d}'.format(epoch, step) +\n","                        ' | loss={:.5f}'.format(avg_loss) +\n","                        ' | ploss={:.5f}'.format(avg_ploss) +\n","                        ' | vloss={:.5f}'.format(avg_vloss) +\n","                        ' | entropy={:.5f}'.format(avg_entropy) +\n","                        ' | reward={:.5f}'.format(avg_reward))\n","        ### END of epoch ###\n","\n","        policy_file = '{}/policy_model_epoch_{}.ckpt'.format(log_dir, epoch)\n","        logger.info(\"Save model to \" + policy_file)\n","        torch.save(model.state_dict(), policy_file)\n","\n","\n","def main(dataset='challenge',name='train_agent',seed=123,gpu='0',epochs=1, batch_size=32,lr=1e-4,max_acts=250,max_path_len=3,\n","    gamma=0.99,ent_weight=1e-3,act_dropout=0.5,state_history=1,hidden=[512, 256]):\n","    os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n","    device = torch.device('cuda:0') if torch.cuda.is_available() else 'cpu'\n","\n","    log_dir = '{}/{}'.format(TMP_DIR['challenge'], name)\n","    if not os.path.isdir(log_dir):\n","        os.makedirs(log_dir)\n","\n","    global logger\n","    logger = get_logger(log_dir + '/train_log.txt')\n","    #logger.info(args)\n","\n","    set_random_seed(seed)\n","    train(dataset='challenge',name='train_agent',seed=123,gpu='0',epochs=1, batch_size=32,lr=1e-4,max_acts=250,max_path_len=3,\n","    gamma=0.99,ent_weight=1e-3,act_dropout=0.5,state_history=1,hidden=[512, 256],device=device,log_dir=log_dir)\n","\n","\n","if __name__ == '__main__':\n","    main(dataset='challenge',name='train_agent',seed=123,gpu='0',epochs=1, batch_size=32,lr=1e-4,max_acts=250,max_path_len=3,\n","    gamma=0.99,ent_weight=1e-3,act_dropout=0.5,state_history=1,hidden=[512, 256])"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"RKf1SgBinF43","executionInfo":{"status":"ok","timestamp":1689085846491,"user_tz":-60,"elapsed":428,"user":{"displayName":"huan chen","userId":"01704466685251061733"}}},"outputs":[],"source":["import argparse\n","from math import log\n","from datetime import datetime\n","from tqdm import tqdm\n","from collections import namedtuple\n","import torch.optim as optim\n","from torch.autograd import Variable\n","from torch.distributions import Categorical\n","import threading\n","from functools import reduce"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XNh_clyTnF43","executionInfo":{"status":"ok","timestamp":1689085871740,"user_tz":-60,"elapsed":22540,"user":{"displayName":"huan chen","userId":"01704466685251061733"}},"outputId":"f636a948-281e-4445-92c6-cc4a32a8e035"},"outputs":[{"output_type":"stream","name":"stdout","text":["Predicting paths...\n","Load embedding: ./tmp/Challenge_Dataset/transe_embed.pkl\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/463 [00:00<?, ?it/s]<ipython-input-9-f55a25594160>:29: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at ../aten/src/ATen/native/cuda/Indexing.cu:1440.)\n","  actor_logits[1 - act_mask] = -999999.0\n","464it [00:21, 21.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Load embedding: ./tmp/Challenge_Dataset/transe_embed.pkl\n","MAP=42.854 | NDCG=60.156 |  Recall=24.605 | Precision=59.957\n"]}],"source":["def evaluate(topk_matches, test_user_articles):\n","    \"\"\"Compute metrics for predicted recommendations.\n","    Args:\n","        topk_matches: a list or dict of product ids in ascending order.\n","    \"\"\"\n","    invalid_users = []\n","    # Compute metrics\n","    precisions, recalls, ndcgs, hits, map_scores = [], [], [], [], []\n","    test_user_idxs = list(test_user_articles.keys())\n","    pred_real_articles,pred_l,real_l=[],[],[]\n","    for uid in test_user_idxs:\n","        if uid not in topk_matches or len(topk_matches[uid]) < 10:\n","            invalid_users.append(uid)\n","            continue\n","        pred_list, rel_set = topk_matches[uid][::-1], test_user_articles[uid]\n","        #print(\"uid:\",uid,\"pred_list:\",pred_list,\"real_set:\",rel_set)\n","        pred_real = \"uid:\"+str(uid)+' '+\"pred_list:\"+str(pred_list)+' '+\"rel_set:\"+str(rel_set)\n","        pred_real_articles.append(pred_real)\n","        pred_l.append(pred_list)\n","        real_l.append(rel_set)\n","        #print(pred_real_articles)\n","        if len(pred_list) == 0:\n","            continue\n","        #print(\"uid:\",uid, \"pred_list:\",pred_list, \"rel_set:\",rel_set)\n","\n","        dcg = 0.0\n","        hit_num = 0.0\n","        for i in range(len(pred_list)):\n","            if pred_list[i] in rel_set:\n","                dcg += 1. / (log(i + 2) / log(2))\n","                hit_num += 1\n","        # idcg\n","        idcg = 0.0\n","        for i in range(min(len(rel_set), len(pred_list))):\n","            idcg += 1. / (log(i + 2) / log(2))\n","        ndcg = dcg / idcg\n","        recall = hit_num / len(rel_set)\n","        precision = hit_num / len(pred_list)\n","        hit = 1.0 if hit_num > 0.0 else 0.0\n","\n","        #map\n","        map_score = 0.0\n","        num_hits = 0.0\n","        score = 0.0\n","        for i,p in enumerate(pred_list):\n","            if p in rel_set and p not in pred_list[:i]:\n","                num_hits+=1.0\n","                score+=num_hits/(i+1.0)\n","        map_score = score/min(len(rel_set),10)\n","\n","        ndcgs.append(ndcg)\n","        recalls.append(recall)\n","        precisions.append(precision)\n","        hits.append(hit)\n","        map_scores.append(map_score)\n","\n","    with open(TMP_DIR['challenge'] + '/' +'pred_real_article.dat','wb+') as file:\n","        pickle.dump(pred_real_articles,file)\n","\n","    with open(TMP_DIR['challenge'] + '/' +'pred_list.dat','wb+') as file:\n","        pickle.dump(pred_l,file)\n","\n","    with open(TMP_DIR['challenge'] + '/' +'real_list.dat','wb+') as file:\n","        pickle.dump(real_l,file)\n","\n","    avg_precision = np.mean(precisions) * 100\n","    avg_recall = np.mean(recalls) * 100\n","    avg_ndcg = np.mean(ndcgs) * 100\n","    avg_hit = np.mean(hits) * 100\n","    avg_map = np.mean(map_scores) * 100\n","\n","    tmp = 'map: '+str(avg_map)+' '+'ndcg: '+str(avg_ndcg)+ ' '+'recall: '+str(avg_recall)+' '+'precision: '+str(avg_precision)+' '+str(len(invalid_users))\n","    pickle.dump(tmp, open(log_dir + '/result.txt', 'wb'))\n","\n","    print('MAP={:.3f} | NDCG={:.3f} |  Recall={:.3f} | Precision={:.3f}'.format(\n","            avg_map, avg_ndcg, avg_recall, avg_precision))\n","\n","\n","def batch_beam_search(env, model, uids, device, topk=[25, 5, 1]):\n","    def _batch_acts_to_masks(batch_acts):\n","        batch_masks = []\n","        for acts in batch_acts:\n","            num_acts = len(acts)\n","            act_mask = np.zeros(model.act_dim, dtype=np.uint8)\n","            act_mask[:num_acts] = 1\n","            batch_masks.append(act_mask)\n","        return np.vstack(batch_masks)\n","\n","    state_pool = env.reset(uids)  # numpy of [bs, dim]\n","    path_pool = env._batch_path  # list of list, size=bs\n","    probs_pool = [[] for _ in uids]\n","    model.eval()\n","    for hop in range(3):\n","        state_tensor = torch.FloatTensor(state_pool).to(device)\n","        acts_pool = env._batch_get_actions(path_pool, False)  # list of list, size=bs\n","        actmask_pool = _batch_acts_to_masks(acts_pool)  # numpy of [bs, dim]\n","        actmask_tensor = torch.ByteTensor(actmask_pool).to(device)\n","        probs, _ = model((state_tensor, actmask_tensor))  # Tensor of [bs, act_dim]\n","        probs = probs + actmask_tensor.float()  # In order to differ from masked actions\n","        topk_probs, topk_idxs = torch.topk(probs, topk[hop], dim=1)  # LongTensor of [bs, k]\n","        topk_idxs = topk_idxs.detach().cpu().numpy()\n","        topk_probs = topk_probs.detach().cpu().numpy()\n","\n","        new_path_pool, new_probs_pool = [], []\n","        for row in range(topk_idxs.shape[0]):\n","            path = path_pool[row]\n","            probs = probs_pool[row]\n","            for idx, p in zip(topk_idxs[row], topk_probs[row]):\n","                if idx >= len(acts_pool[row]):  # act idx is invalid\n","                    continue\n","                relation, next_node_id = acts_pool[row][idx]  # (relation, next_node_id)\n","                if relation == SELF_LOOP:\n","                    next_node_type = path[-1][1]\n","                else:\n","                    next_node_type = KG_RELATION[path[-1][1]][relation]\n","                new_path = path + [(relation, next_node_type, next_node_id)]\n","                new_path_pool.append(new_path)\n","                new_probs_pool.append(probs + [p])\n","        path_pool = new_path_pool\n","        probs_pool = new_probs_pool\n","        if hop < 2:\n","            state_pool = env._batch_get_state(path_pool)\n","\n","    return path_pool, probs_pool\n","\n","\n","def predict_paths(policy_file, path_file, dataset='challenge',name='train_agent',log_dir='./', device='cuda', seed=123,gpu='0',epochs=1,max_acts=250,max_path_len=5,\n","         gamma=0.99,state_history=1,hidden=[512,256],add_articles=False,topk=[25, 5, 1],run_path=True,run_eval=True):\n","    print('Predicting paths...')\n","    env = BatchKGEnvironment(dataset, max_acts, max_path_len=max_path_len, state_history=state_history)\n","    pretrain_sd = torch.load(policy_file, map_location=torch.device('cpu'))\n","    #print(env.state_dim,env.act_dim)\n","    model = ActorCritic(env.state_dim, env.act_dim, gamma=gamma, hidden_sizes=hidden).to(device)\n","    model_sd = model.state_dict()\n","    model_sd.update(pretrain_sd)\n","    model.load_state_dict(model_sd)\n","\n","    test_labels = load_labels(dataset, 'test')\n","    test_uids = list(test_labels.keys())\n","\n","    batch_size = 16\n","    start_idx = 0\n","    all_paths, all_probs = [], []\n","    pbar = tqdm(total=len(test_uids))\n","    while start_idx < len(test_uids):\n","        end_idx = min(start_idx + batch_size, len(test_uids))\n","        batch_uids = test_uids[start_idx:end_idx]\n","        paths, probs = batch_beam_search(env, model, batch_uids, device, topk=topk)\n","        all_paths.extend(paths)\n","        all_probs.extend(probs)\n","        start_idx = end_idx\n","        pbar.update(batch_size)\n","    predicts = {'paths': all_paths, 'probs': all_probs}\n","    pickle.dump(predicts, open(path_file, 'wb'))\n","\n","\n","def evaluate_paths(path_file, train_labels, test_labels, add_articles=False):\n","    embeds = load_embed('challenge')\n","    user_embeds = embeds[USER]\n","    response_embeds = embeds[ARTICLE][0]\n","    article_embeds = embeds[ARTICLE]\n","    scores = np.dot(user_embeds + response_embeds, article_embeds.T)\n","\n","    # 1) Get all valid paths for each user, compute path score and path probability.\n","    results = pickle.load(open(path_file, 'rb'))\n","    #print(\"result_path:\",results['paths'])\n","    pred_paths = {uid: {} for uid in test_labels}\n","    for path, probs in zip(results['paths'], results['probs']):\n","        if path[-1][1] != ARTICLE:\n","            continue\n","        uid = path[0][2]\n","        if uid not in pred_paths:\n","            continue\n","        aid = path[-1][2]\n","        if aid not in pred_paths[uid]:\n","            pred_paths[uid][aid] = []\n","        path_score = scores[uid][aid]\n","        path_prob = reduce(lambda x, y: x * y, probs)\n","        pred_paths[uid][aid].append((path_score, path_prob, path))\n","\n","    # 2) Pick best path for each user-product pair, also remove pid if it is in train set.\n","    best_pred_paths = {}\n","    for uid in pred_paths:\n","        if uid in train_labels:\n","            train_aids = set(train_labels[uid])\n","            best_pred_paths[uid] = []\n","            for aid in pred_paths[uid]:\n","                if aid in train_aids:\n","                    continue\n","                # Get the path with highest probability\n","                #print(\"pred_path:\",pred_paths)\n","                sorted_path = sorted(pred_paths[uid][aid], key=lambda x: x[1], reverse=True)\n","                best_pred_paths[uid].append(sorted_path[0])\n","    #print(\"best_pred_path:\",best_pred_paths)\n","\n","    with open(TMP_DIR['challenge'] + '/' +'best_pred_path.dat','wb+') as file:\n","        pickle.dump(best_pred_paths,file)\n","\n","    # 3) Compute top 10 recommended articls for each user.\n","    top10_pred_paths = {}\n","    sort_by = 'score'\n","    pred_labels = {}\n","    for uid in best_pred_paths:\n","\n","        top10_pred_paths[uid] = []\n","\n","        if sort_by == 'score':\n","            sorted_path = sorted(best_pred_paths[uid], key=lambda x: (x[0], x[1]), reverse=True)\n","        elif sort_by == 'prob':\n","            sorted_path = sorted(best_pred_paths[uid], key=lambda x: (x[1], x[0]), reverse=True)\n","\n","        top10_pred_paths[uid].append(sorted_path[:10])\n","\n","        top10_aids = [p[-1][2] for _, _, p in sorted_path[:10]]  # from largest to smallest\n","        # add up to 10 pids if not enough\n","        if add_articles and len(top10_aids) < 10:\n","            train_aids = set(train_labels[uid])\n","            cand_aids = np.argsort(scores[uid])\n","            for cand_aid in cand_aids[::-1]:\n","                if cand_aid in train_aids or cand_aid in top10_aids:\n","                    continue\n","                top10_aids.append(cand_aid)\n","                if len(top10_aids) >= 10:\n","                    break\n","        # end of add\n","        pred_labels[uid] = top10_aids[::-1]  # change order to from smallest to largest!\n","\n","    with open(TMP_DIR['challenge'] + '/' +'top10_pred_paths.dat','wb+') as file:\n","        pickle.dump(top10_pred_paths,file)\n","\n","    evaluate(pred_labels, test_labels)\n","\n","\n","def test(dataset='challenge',name='train_agent',log_dir='./', device='cuda', seed=123,gpu='0',epochs=1,max_acts=250,max_path_len=5,\n","         gamma=0.99,state_history=1,hidden=[512,256],add_articles=False,topk=[25, 5, 1],run_path=True,run_eval=True):\n","\n","    policy_file = log_dir + '/policy_model_epoch_{}.ckpt'.format(epochs)\n","    path_file = log_dir + '/policy_paths_epoch{}.pkl'.format(epochs)\n","\n","    train_labels = load_labels(dataset, 'train')\n","    test_labels = load_labels(dataset, 'test')\n","\n","    if run_path:\n","        predict_paths(policy_file, path_file, dataset='challenge',name='train_agent',log_dir='./', device='cuda', seed=123,gpu='0',epochs=1,max_acts=250,max_path_len=5,\n","         gamma=0.99,state_history=1,hidden=[512,256],add_articles=False,topk=[25, 5, 1],run_path=True,run_eval=True)\n","    if run_eval:\n","        evaluate_paths(path_file, train_labels, test_labels)\n","\n","\n","if __name__ == '__main__':\n","    boolean = lambda x: (str(x).lower() == 'true')\n","    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n","    device = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n","\n","    log_dir = TMP_DIR['challenge'] + '/' + 'train_agent'\n","    test(dataset='challenge',name='train_agent',log_dir=log_dir, device=device, seed=123,gpu='0',epochs=1,max_acts=250,max_path_len=5,\n","         gamma=0.99,state_history=1,hidden=[512,256],add_articles=False,topk=[25, 5, 1],run_path=True,run_eval=True)"]}],"metadata":{"instance_type":"ml.g4dn.12xlarge","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"lcc_arn":"arn:aws:sagemaker:us-east-1:647324198242:studio-lifecycle-config/dlsg-sagemaker-kernel-on-start-e8130f","colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}